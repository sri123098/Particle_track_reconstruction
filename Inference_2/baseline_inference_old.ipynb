{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 256, 256, 6)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 256, 256, 64)      3520      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 256, 256, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 256, 256, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 128, 128, 128)     512       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 128, 128, 128)     512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 64, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 64, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 16, 16, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 16, 16, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 16, 16, 1024)      9438208   \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 16, 16, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 8, 8, 512)         4719104   \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 4, 4, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 65,511,681\n",
      "Trainable params: 65,482,241\n",
      "Non-trainable params: 29,440\n",
      "_________________________________________________________________\n",
      "y_hat mean:0.275551 median:0.251014\n",
      "Sensitive TP/(TP+FN) : 0.590000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59       100\n",
      "           1       0.59      0.59      0.59       100\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       200\n",
      "   macro avg       0.59      0.59      0.59       200\n",
      "weighted avg       0.59      0.59      0.59       200\n",
      "\n",
      "y_hat mean:0.279528 median:0.247089\n",
      "Sensitive TP/(TP+FN) : 0.580000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58       100\n",
      "           1       0.58      0.58      0.58       100\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       200\n",
      "   macro avg       0.58      0.58      0.58       200\n",
      "weighted avg       0.58      0.58      0.58       200\n",
      "\n",
      "y_hat mean:0.253490 median:0.200003\n",
      "Sensitive TP/(TP+FN) : 0.590000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59       100\n",
      "           1       0.59      0.59      0.59       100\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       200\n",
      "   macro avg       0.59      0.59      0.59       200\n",
      "weighted avg       0.59      0.59      0.59       200\n",
      "\n",
      "y_hat mean:0.281412 median:0.257304\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.269237 median:0.221511\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat mean:0.244987 median:0.206040\n",
      "Sensitive TP/(TP+FN) : 0.600000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60       100\n",
      "           1       0.60      0.60      0.60       100\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       200\n",
      "   macro avg       0.60      0.60      0.60       200\n",
      "weighted avg       0.60      0.60      0.60       200\n",
      "\n",
      "y_hat mean:0.265588 median:0.246752\n",
      "Sensitive TP/(TP+FN) : 0.590000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59       100\n",
      "           1       0.59      0.59      0.59       100\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       200\n",
      "   macro avg       0.59      0.59      0.59       200\n",
      "weighted avg       0.59      0.59      0.59       200\n",
      "\n",
      "y_hat mean:0.243653 median:0.208644\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.254069 median:0.236925\n",
      "Sensitive TP/(TP+FN) : 0.610000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       100\n",
      "           1       0.61      0.61      0.61       100\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       200\n",
      "   macro avg       0.61      0.61      0.61       200\n",
      "weighted avg       0.61      0.61      0.61       200\n",
      "\n",
      "y_hat mean:0.277588 median:0.277291\n",
      "Sensitive TP/(TP+FN) : 0.650000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       100\n",
      "           1       0.65      0.65      0.65       100\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.65      0.65      0.65       200\n",
      "\n",
      "y_hat mean:0.253585 median:0.212764\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.260527 median:0.224493\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.274748 median:0.253469\n",
      "Sensitive TP/(TP+FN) : 0.590000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59       100\n",
      "           1       0.59      0.59      0.59       100\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       200\n",
      "   macro avg       0.59      0.59      0.59       200\n",
      "weighted avg       0.59      0.59      0.59       200\n",
      "\n",
      "y_hat mean:0.254862 median:0.198986\n",
      "Sensitive TP/(TP+FN) : 0.680000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68       100\n",
      "           1       0.68      0.68      0.68       100\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       200\n",
      "   macro avg       0.68      0.68      0.68       200\n",
      "weighted avg       0.68      0.68      0.68       200\n",
      "\n",
      "y_hat mean:0.249010 median:0.223106\n",
      "Sensitive TP/(TP+FN) : 0.610000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       100\n",
      "           1       0.61      0.61      0.61       100\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       200\n",
      "   macro avg       0.61      0.61      0.61       200\n",
      "weighted avg       0.61      0.61      0.61       200\n",
      "\n",
      "y_hat mean:0.271410 median:0.239659\n",
      "Sensitive TP/(TP+FN) : 0.650000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       100\n",
      "           1       0.65      0.65      0.65       100\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.65      0.65      0.65       200\n",
      "\n",
      "y_hat mean:0.268886 median:0.236673\n",
      "Sensitive TP/(TP+FN) : 0.580000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58       100\n",
      "           1       0.58      0.58      0.58       100\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       200\n",
      "   macro avg       0.58      0.58      0.58       200\n",
      "weighted avg       0.58      0.58      0.58       200\n",
      "\n",
      "y_hat mean:0.259145 median:0.228996\n",
      "Sensitive TP/(TP+FN) : 0.580000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58       100\n",
      "           1       0.58      0.58      0.58       100\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       200\n",
      "   macro avg       0.58      0.58      0.58       200\n",
      "weighted avg       0.58      0.58      0.58       200\n",
      "\n",
      "y_hat mean:0.273292 median:0.240729\n",
      "Sensitive TP/(TP+FN) : 0.670000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67       100\n",
      "           1       0.67      0.67      0.67       100\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.67      0.67      0.67       200\n",
      "\n",
      "y_hat mean:0.263696 median:0.233341\n",
      "Sensitive TP/(TP+FN) : 0.610000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       100\n",
      "           1       0.61      0.61      0.61       100\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       200\n",
      "   macro avg       0.61      0.61      0.61       200\n",
      "weighted avg       0.61      0.61      0.61       200\n",
      "\n",
      "y_hat mean:0.256926 median:0.201224\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.275521 median:0.236133\n",
      "Sensitive TP/(TP+FN) : 0.570000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.57      0.57       100\n",
      "           1       0.57      0.57      0.57       100\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       200\n",
      "   macro avg       0.57      0.57      0.57       200\n",
      "weighted avg       0.57      0.57      0.57       200\n",
      "\n",
      "y_hat mean:0.236570 median:0.200474\n",
      "Sensitive TP/(TP+FN) : 0.590000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59       100\n",
      "           1       0.59      0.59      0.59       100\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       200\n",
      "   macro avg       0.59      0.59      0.59       200\n",
      "weighted avg       0.59      0.59      0.59       200\n",
      "\n",
      "y_hat mean:0.255860 median:0.202748\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "y_hat mean:0.265823 median:0.236802\n",
      "Sensitive TP/(TP+FN) : 0.670000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67       100\n",
      "           1       0.67      0.67      0.67       100\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.67      0.67      0.67       200\n",
      "\n",
      "y_hat mean:0.251672 median:0.208430\n",
      "Sensitive TP/(TP+FN) : 0.700000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70       100\n",
      "           1       0.70      0.70      0.70       100\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       200\n",
      "   macro avg       0.70      0.70      0.70       200\n",
      "weighted avg       0.70      0.70      0.70       200\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat mean:0.272788 median:0.240330\n",
      "Sensitive TP/(TP+FN) : 0.590000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59       100\n",
      "           1       0.59      0.59      0.59       100\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       200\n",
      "   macro avg       0.59      0.59      0.59       200\n",
      "weighted avg       0.59      0.59      0.59       200\n",
      "\n",
      "y_hat mean:0.266517 median:0.243778\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.255215 median:0.228598\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "y_hat mean:0.260265 median:0.228439\n",
      "Sensitive TP/(TP+FN) : 0.690000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       100\n",
      "           1       0.69      0.69      0.69       100\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       200\n",
      "   macro avg       0.69      0.69      0.69       200\n",
      "weighted avg       0.69      0.69      0.69       200\n",
      "\n",
      "y_hat mean:0.261550 median:0.240530\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.266392 median:0.237304\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.258308 median:0.235786\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.257081 median:0.223674\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.275588 median:0.249648\n",
      "Sensitive TP/(TP+FN) : 0.600000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60       100\n",
      "           1       0.60      0.60      0.60       100\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       200\n",
      "   macro avg       0.60      0.60      0.60       200\n",
      "weighted avg       0.60      0.60      0.60       200\n",
      "\n",
      "y_hat mean:0.273762 median:0.239926\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.254772 median:0.234665\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.261426 median:0.228242\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.251273 median:0.202314\n",
      "Sensitive TP/(TP+FN) : 0.700000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70       100\n",
      "           1       0.70      0.70      0.70       100\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       200\n",
      "   macro avg       0.70      0.70      0.70       200\n",
      "weighted avg       0.70      0.70      0.70       200\n",
      "\n",
      "y_hat mean:0.236337 median:0.212436\n",
      "Sensitive TP/(TP+FN) : 0.690000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       100\n",
      "           1       0.69      0.69      0.69       100\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       200\n",
      "   macro avg       0.69      0.69      0.69       200\n",
      "weighted avg       0.69      0.69      0.69       200\n",
      "\n",
      "y_hat mean:0.265255 median:0.217825\n",
      "Sensitive TP/(TP+FN) : 0.700000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70       100\n",
      "           1       0.70      0.70      0.70       100\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       200\n",
      "   macro avg       0.70      0.70      0.70       200\n",
      "weighted avg       0.70      0.70      0.70       200\n",
      "\n",
      "y_hat mean:0.274707 median:0.241453\n",
      "Sensitive TP/(TP+FN) : 0.650000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       100\n",
      "           1       0.65      0.65      0.65       100\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.65      0.65      0.65       200\n",
      "\n",
      "y_hat mean:0.270511 median:0.235621\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.263876 median:0.230579\n",
      "Sensitive TP/(TP+FN) : 0.650000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       100\n",
      "           1       0.65      0.65      0.65       100\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.65      0.65      0.65       200\n",
      "\n",
      "y_hat mean:0.273018 median:0.236355\n",
      "Sensitive TP/(TP+FN) : 0.670000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67       100\n",
      "           1       0.67      0.67      0.67       100\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.67      0.67      0.67       200\n",
      "\n",
      "y_hat mean:0.245153 median:0.197607\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.248892 median:0.212732\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat mean:0.252559 median:0.217235\n",
      "Sensitive TP/(TP+FN) : 0.580000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58       100\n",
      "           1       0.58      0.58      0.58       100\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       200\n",
      "   macro avg       0.58      0.58      0.58       200\n",
      "weighted avg       0.58      0.58      0.58       200\n",
      "\n",
      "y_hat mean:0.300461 median:0.282490\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.253480 median:0.221922\n",
      "Sensitive TP/(TP+FN) : 0.700000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70       100\n",
      "           1       0.70      0.70      0.70       100\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       200\n",
      "   macro avg       0.70      0.70      0.70       200\n",
      "weighted avg       0.70      0.70      0.70       200\n",
      "\n",
      "y_hat mean:0.251960 median:0.230677\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "y_hat mean:0.260942 median:0.219186\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.264444 median:0.241894\n",
      "Sensitive TP/(TP+FN) : 0.580000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58       100\n",
      "           1       0.58      0.58      0.58       100\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       200\n",
      "   macro avg       0.58      0.58      0.58       200\n",
      "weighted avg       0.58      0.58      0.58       200\n",
      "\n",
      "y_hat mean:0.282687 median:0.265391\n",
      "Sensitive TP/(TP+FN) : 0.590000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59       100\n",
      "           1       0.59      0.59      0.59       100\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       200\n",
      "   macro avg       0.59      0.59      0.59       200\n",
      "weighted avg       0.59      0.59      0.59       200\n",
      "\n",
      "y_hat mean:0.268061 median:0.230130\n",
      "Sensitive TP/(TP+FN) : 0.550000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.55      0.55       100\n",
      "           1       0.55      0.55      0.55       100\n",
      "\n",
      "   micro avg       0.55      0.55      0.55       200\n",
      "   macro avg       0.55      0.55      0.55       200\n",
      "weighted avg       0.55      0.55      0.55       200\n",
      "\n",
      "y_hat mean:0.252054 median:0.226805\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.278124 median:0.248445\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "y_hat mean:0.254997 median:0.209945\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "y_hat mean:0.252760 median:0.221847\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.249277 median:0.215267\n",
      "Sensitive TP/(TP+FN) : 0.600000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60       100\n",
      "           1       0.60      0.60      0.60       100\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       200\n",
      "   macro avg       0.60      0.60      0.60       200\n",
      "weighted avg       0.60      0.60      0.60       200\n",
      "\n",
      "y_hat mean:0.258447 median:0.216769\n",
      "Sensitive TP/(TP+FN) : 0.670000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67       100\n",
      "           1       0.67      0.67      0.67       100\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.67      0.67      0.67       200\n",
      "\n",
      "y_hat mean:0.262030 median:0.246299\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.245640 median:0.204011\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "y_hat mean:0.262648 median:0.204912\n",
      "Sensitive TP/(TP+FN) : 0.650000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       100\n",
      "           1       0.65      0.65      0.65       100\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.65      0.65      0.65       200\n",
      "\n",
      "y_hat mean:0.246770 median:0.224789\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.273652 median:0.243385\n",
      "Sensitive TP/(TP+FN) : 0.670000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67       100\n",
      "           1       0.67      0.67      0.67       100\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.67      0.67      0.67       200\n",
      "\n",
      "y_hat mean:0.250878 median:0.226232\n",
      "Sensitive TP/(TP+FN) : 0.670000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67       100\n",
      "           1       0.67      0.67      0.67       100\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.67      0.67      0.67       200\n",
      "\n",
      "y_hat mean:0.254892 median:0.212526\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat mean:0.269450 median:0.240786\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.242707 median:0.213230\n",
      "Sensitive TP/(TP+FN) : 0.670000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67       100\n",
      "           1       0.67      0.67      0.67       100\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.67      0.67      0.67       200\n",
      "\n",
      "y_hat mean:0.263461 median:0.222439\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.255534 median:0.214086\n",
      "Sensitive TP/(TP+FN) : 0.590000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59       100\n",
      "           1       0.59      0.59      0.59       100\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       200\n",
      "   macro avg       0.59      0.59      0.59       200\n",
      "weighted avg       0.59      0.59      0.59       200\n",
      "\n",
      "y_hat mean:0.274381 median:0.235544\n",
      "Sensitive TP/(TP+FN) : 0.610000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       100\n",
      "           1       0.61      0.61      0.61       100\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       200\n",
      "   macro avg       0.61      0.61      0.61       200\n",
      "weighted avg       0.61      0.61      0.61       200\n",
      "\n",
      "y_hat mean:0.282682 median:0.258781\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "y_hat mean:0.250037 median:0.210052\n",
      "Sensitive TP/(TP+FN) : 0.600000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60       100\n",
      "           1       0.60      0.60      0.60       100\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       200\n",
      "   macro avg       0.60      0.60      0.60       200\n",
      "weighted avg       0.60      0.60      0.60       200\n",
      "\n",
      "y_hat mean:0.254750 median:0.239766\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.256616 median:0.212119\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.279863 median:0.253545\n",
      "Sensitive TP/(TP+FN) : 0.600000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60       100\n",
      "           1       0.60      0.60      0.60       100\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       200\n",
      "   macro avg       0.60      0.60      0.60       200\n",
      "weighted avg       0.60      0.60      0.60       200\n",
      "\n",
      "y_hat mean:0.268116 median:0.231429\n",
      "Sensitive TP/(TP+FN) : 0.650000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       100\n",
      "           1       0.65      0.65      0.65       100\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.65      0.65      0.65       200\n",
      "\n",
      "y_hat mean:0.253648 median:0.205542\n",
      "Sensitive TP/(TP+FN) : 0.670000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67       100\n",
      "           1       0.67      0.67      0.67       100\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.67      0.67      0.67       200\n",
      "\n",
      "y_hat mean:0.247715 median:0.189972\n",
      "Sensitive TP/(TP+FN) : 0.690000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       100\n",
      "           1       0.69      0.69      0.69       100\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       200\n",
      "   macro avg       0.69      0.69      0.69       200\n",
      "weighted avg       0.69      0.69      0.69       200\n",
      "\n",
      "y_hat mean:0.245506 median:0.206439\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.270523 median:0.238420\n",
      "Sensitive TP/(TP+FN) : 0.650000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       100\n",
      "           1       0.65      0.65      0.65       100\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.65      0.65      0.65       200\n",
      "\n",
      "y_hat mean:0.250091 median:0.229570\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "y_hat mean:0.260246 median:0.205486\n",
      "Sensitive TP/(TP+FN) : 0.720000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.72      0.72       100\n",
      "           1       0.72      0.72      0.72       100\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       200\n",
      "   macro avg       0.72      0.72      0.72       200\n",
      "weighted avg       0.72      0.72      0.72       200\n",
      "\n",
      "y_hat mean:0.242606 median:0.212830\n",
      "Sensitive TP/(TP+FN) : 0.680000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68       100\n",
      "           1       0.68      0.68      0.68       100\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       200\n",
      "   macro avg       0.68      0.68      0.68       200\n",
      "weighted avg       0.68      0.68      0.68       200\n",
      "\n",
      "y_hat mean:0.272992 median:0.265210\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.266520 median:0.224455\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.252320 median:0.216925\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat mean:0.275471 median:0.254280\n",
      "Sensitive TP/(TP+FN) : 0.670000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67       100\n",
      "           1       0.67      0.67      0.67       100\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.67      0.67      0.67       200\n",
      "\n",
      "y_hat mean:0.252549 median:0.224062\n",
      "Sensitive TP/(TP+FN) : 0.690000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       100\n",
      "           1       0.69      0.69      0.69       100\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       200\n",
      "   macro avg       0.69      0.69      0.69       200\n",
      "weighted avg       0.69      0.69      0.69       200\n",
      "\n",
      "y_hat mean:0.258760 median:0.218606\n",
      "Sensitive TP/(TP+FN) : 0.650000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       100\n",
      "           1       0.65      0.65      0.65       100\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.65      0.65      0.65       200\n",
      "\n",
      "y_hat mean:0.262774 median:0.216657\n",
      "Sensitive TP/(TP+FN) : 0.710000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71       100\n",
      "           1       0.71      0.71      0.71       100\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       200\n",
      "   macro avg       0.71      0.71      0.71       200\n",
      "weighted avg       0.71      0.71      0.71       200\n",
      "\n",
      "y_hat mean:0.248408 median:0.204339\n",
      "Sensitive TP/(TP+FN) : 0.730000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73       100\n",
      "           1       0.73      0.73      0.73       100\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       200\n",
      "   macro avg       0.73      0.73      0.73       200\n",
      "weighted avg       0.73      0.73      0.73       200\n",
      "\n",
      "y_hat mean:0.248611 median:0.222701\n",
      "Sensitive TP/(TP+FN) : 0.560000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56       100\n",
      "           1       0.56      0.56      0.56       100\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       200\n",
      "   macro avg       0.56      0.56      0.56       200\n",
      "weighted avg       0.56      0.56      0.56       200\n",
      "\n",
      "y_hat mean:0.254005 median:0.231737\n",
      "Sensitive TP/(TP+FN) : 0.680000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68       100\n",
      "           1       0.68      0.68      0.68       100\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       200\n",
      "   macro avg       0.68      0.68      0.68       200\n",
      "weighted avg       0.68      0.68      0.68       200\n",
      "\n",
      "y_hat mean:0.237875 median:0.199467\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.259763 median:0.234002\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.250055 median:0.222834\n",
      "Sensitive TP/(TP+FN) : 0.590000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59       100\n",
      "           1       0.59      0.59      0.59       100\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       200\n",
      "   macro avg       0.59      0.59      0.59       200\n",
      "weighted avg       0.59      0.59      0.59       200\n",
      "\n",
      "y_hat mean:0.250209 median:0.206509\n",
      "Sensitive TP/(TP+FN) : 0.650000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       100\n",
      "           1       0.65      0.65      0.65       100\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.65      0.65      0.65       200\n",
      "\n",
      "y_hat mean:0.251504 median:0.227506\n",
      "Sensitive TP/(TP+FN) : 0.600000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60       100\n",
      "           1       0.60      0.60      0.60       100\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       200\n",
      "   macro avg       0.60      0.60      0.60       200\n",
      "weighted avg       0.60      0.60      0.60       200\n",
      "\n",
      "(20200, 1)\n",
      "(20200, 1)\n",
      "y_hat mean:0.500000 median:0.500000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xd4FWX2wPHvIQQSOpjQQgkgvQlERBHFxYKNoqJgAVZ+6u6KuujaVteCunZ3RVwLawFWRVRAUBALKIqCoCCS0EIQCL0XQ0k5vz/e4XIJSbhAbuYmOZ/nuU/mvjN35sxNcs+deWfOK6qKMcYYA1DG7wCMMcZEDksKxhhjAiwpGGOMCbCkYIwxJsCSgjHGmABLCsYYYwIsKRhjjAmwpGCMMSbAkoIxxpiAsn4HcLzi4uI0MTHR7zCMMaZY+emnn7aqavyxlit2SSExMZH58+f7HYYxxhQrIrI6lOXs9JExxpgASwrGGGMCLCkYY4wJsKRgjDEmwJKCMcaYgLAlBRF5U0Q2i8jifOaLiIwQkVQRWSQiHcMVizHGmNCE85LUt4GRwJh85l8MNPUeZwCveD9PWE5ODlu3bmXnzp1kZ2efzKqMMYUsKiqKatWqERcXR5kydpLihKiCSFg3EbakoKqzRCSxgEV6A2PUjQc6R0SqiUgdVd1wottMT09HREhMTCQ6OhoJ85tnjAmNqpKZmcmmTZtIT0+nQYMGfodUfOzfCcvHQ/JoaHolJN0Z1s35efNaArA26Hm613ZUUhCRm4GbgQL/mH7//XeaN29u30KMiTAiQrly5UhISGDZsmV+hxP5crJg9RcuEaROguwDrl1zSnRSCJmqvg68DpCUlKQFLWsJwZjIZf+fx7B1sUsES/4Hv2/0GgUa/AFaDYKmV4Q9BD+TwjqgftDzel6bMcaUHhlbYem7Lhls/vlwe/WmLhG0ugGqFN3pNj+TwmRgqIiMw3Uw7zqZ/gRjjCk2sg9C2lRIfhtWfepOFwGUrwrN+0PrQVCnS9g7lfMStqQgIu8B3YE4EUkHHgaiAVT1VWAqcAmQCmQAfwxXLKZk2rt3L82bN2fSpEmcfvrpfodTqr333nu88MIL/Pjjj3aBR35U3ZFA8mhY8i7s3+bapQw0usQlgia9oGyMr2GG7QSfqg5Q1TqqGq2q9VT1DVV91UsIqHOrqjZR1baqWqpLnw4ePBgRQUSIioqiXr16DBw4kHXrjj6jtnLlSgYPHkxCQgLlypWjbt26DBo0iJUrVx61bEZGBo8//jjt2rWjQoUK1KhRgzPOOIOXXnqJjIyMoti1sHn66adJSkoqFQlh7ty5nHXWWcTExFCnTh3uv//+kC67Xr16Nddddx1xcXHExMTQvHlzpkyZEpg/duxYOnXqRPXq1YmNjaVly5a88MILuIsCD8vIyOC+++4jMTEx0GE8fPjwwPz+/fuTkZHBO++8U3g7XVLs3QDznoXRbeF/SbDgJZcQ4trAuc/BLevgik+h+dW+JwQoJh3NpUW3bt0YP3482dnZrFy5kltvvZV+/frx/fffB5ZZsGABf/jDH+jUqRPvvvsujRo14rfffuOxxx4jKSmJmTNnctpppwGwe/duzj33XNavX8/w4cM544wzqFq1KvPnz2fEiBHUr1+fPn36FNn+HTx4kHLlyhXKuvbv388rr7zCmDH53QYTGlUlKyuL6OjoQokrHNauXcsFF1zAlVdeyahRo1ixYgU33ngjqspTTz2V7+vWrVtHly5dOO+88/jkk0+oXbs2q1evpkqVKoFlatasyT/+8Q+aN29O+fLl+fbbb/nLX/5CVFQUd9xxBwDZ2dlceuml7N69m9dee43mzZuzbds2tm7dGliPiDBkyBD+/e9/c/3114fvzSguMvfByo/dUcHqz91VQwCxcdDiWndUULODL6eHjklVi9WjU6dOmp+UlJR850W6QYMGaY8ePY5oGzFihAK6a9cuVVXNycnRdu3aadu2bTUzM/OIZTMzM7VNmzbavn17zcnJUVXVoUOHakxMjKalpR21vZycHN2xY0e+8ezZs0fvuOMOrVevnpYrV04bNmyoTzzxhKqqrlq1SgH99ttvj3hNkyZN9OGHHw48B/TFF1/UAQMGaJUqVfTqq6/Ws846S2+66aajtteiRQt94IEHAs/fe+89bd++vZYvX14bNmyow4YN07179wbmT5w4UStUqHDU+/D3v/9dW7RoobGxsVqvXj295ZZbdOfOnYH5b731lkZFRemMGTP0tNNO0+joaJ06daqqqn7++ed61llnaUxMjNatW1cHDx6sW7duDbz2p59+0p49e2p8fLxWrFhRk5KSdNq0afm+h4Xl/vvv14SEBM3Ozg60jRw5UitUqHDEe5LbwIEDtUuXLse9vT59+mifPn0Cz998802tXLmybtq0qcDXpaWlKaBLliwpcLni/H9aoJwc1fTvVKffpPpSVdXncI8XolUn9VVdMUk164Bv4QHzNYTP2JJ/pPC8j5n4rgKvni3Q+vXr+fDDD4mKiiIqKgqARYsWsWjRIsaOHUvZskf+6sqWLcs999zDwIED+fXXX2nTpg3vvPMO1113HY0aNTpq/SJCtWrV8ty2qnLZZZexZs0aXnrpJdq1a0d6evoJXV/+6KOP8uijj/LYY4+Rk5PDzJkzuffee3nppZcoX748AD/++CNLly5l4MCBALz99tsMGzaMESNG0LVrV9LT0xk6dChbtmxh7NixAHzzzTd06NDhqPchNjaW119/nfr16weOtm6//XZGjx4dWCYnJ4d7772XF154gYYNG1K5cmVmzJhB7969efrpp3n77bfZuXMn99xzD1dccQVff/01IsLu3bu55ppreO6554iOjmbMmDH06tWLxYsX06xZs3zfg0qVKh3zfdq7d2++82bPns2FF154xOWcPXv2ZOjQoSxYsICzzz77qNfk5OQwadIkhgwZwoABA/jqq6+oVasW1157LXffffdR7xu43/u8efOYPXs2Dz74YKD9o48+onPnzrz44ouMGTOG6OhoevTowVNPPcUpp5wSWK5Ro0bUrFmTmTNn0qJFi2Puc4mxezUkj4GUMbAz9XB7rSR3RNC8P1SI8y++41Tyk0Ix8vXXX1OpUiVycnLYt28fAHfddRcVK1YECHwot27dOs/XH2pftmwZtWvXZseOHbRq1eq445gxYwbffPMN8+bNIykpCYDGjRtzzjnnHPe6+vTpw9ChQwPP4+PjueOOO5g8eTL9+vUDYMyYMXTp0iXwwfrII4/w5JNPcsMNNwS2PXLkSM4991xGjBhB9erVWbVqFQkJCUdtL/jDLDExkSeffJL+/fvz1ltvBT5UVZXnn3+ebt26BZYdPnw4t99+O7fddlugbfTo0TRs2JBffvmF0047je7dux+xrccff5wpU6bwwQcf8MADD+T7HixcuDDUtytPGzZsoGvXrke01a5dOzAvL1u2bGH37t385z//4dZbb2X69OmkpKRw2223sXfvXp544onAsrt27SIhIYGDBw+Sk5PDww8/zO233x6Yv3LlSlatWkWZMmX44IMP+P333xk2bBh9+vRh1qxZR3QsJyQkkJaWdlL7Wywc3AvLP4SU0bD268PtlepCy+tdMjjl+P/3IkHJTwon8W29qJ1xxhmMHj2a/fv3M378eL788ksef/zxE1qX6onv908//UT16tUDCeFkdO7c+Yjn1apVo1evXowdO5Z+/fqRmZnJuHHjeOyxxwD3YbZ69WruvPNO/va3vwVed2h/UlNTOf3009m3bx9Vq1Y9ansTJkzg3//+N6mpqezevZucnBwOHjzIxo0bqVu3bmC53J3T8+bNY86cOYwcOfKoda5YsYLTTjuNLVu28PDDDzNjxgw2btxIVlYW+/fvZ/Xqgkc5PPXUU4/xLhW+nBx3Drtt27Y8//zzAHTo0IENGzbw2GOPHZEUKleuzMKFC8nIyOD777/n/vvvp27dugwZMiSwLlVl3Lhx1KhRA4A333yT008/nQULFtCx4+FaljExMYEvNCWO5rgEkDzaJYQs70KNsjFwal+XCBqcD2WifA3zZJX8pFCMxMbGBj5A2rRpw8qVK7ntttsYNWoUQOCb9OLFi+nQocNRr09OTgagefPmxMfHU716dVJSUgo9zuBv3MEyMzOPWvbQUU6wgQMH0rdvX7Zs2cLs2bPZu3cv/fv3Bw5/mL344oucd955R722Xr16gDvi2L59+xHz5s6dS79+/bj//vt59tlnqV69OnPmzGHQoEEcPHgwsFxUVBQxMUde5XHolNKho5Ngh76VDx48mDVr1vDMM8/QqFEjYmNj6d+//xHrzsvJnj6qU6cOGzduPKJt06ZNgXl5iYuLIzo6+qijytatW7N792527NhB9erVAff7PPR3165dO3bs2MEDDzwQSAp16tThwIEDgYRwaD3grm4KTgrbt28nPv6YY8MXL9uXu1NDKWNhz5rD7XW7eqeHrnb3F5QQlhQi2COPPELLli255ZZbSEpKon379rRp04Znn32WAQMGHHFeOCsri2effZZ27drRtm1bRIRrr72WN954gwceeOCofgVVZffu3Xl+2+7UqRM7duxg/vz5eR4tHPqnX79+faBt8+bNeV4+m5eLLrqIGjVqMG7cOGbOnMlll10W+ICqVasW9evXZ9myZdx00035rqNjx45Hfav/7rvviIuLO+Lo6sMPPwwppqSkJJKTkwv8Vj9r1iyeeeYZevXqBbhaW2lpabRp06bAdZ/s6aOuXbsyduxYcnJyAgn5s88+o0KFCnl+OQCIjo7mjDPOYOnSpUe0L1u2jKpVqwbe77zk5OSwf//+wPNu3brxww8/sGvXrsDfy6FTmYmJiYHlMjIyWLlyZaEcYfpu/05Y9r47Ktjww+H2Kg2h1UD3qF70R4BFIpTe6Eh6lKarj1TdlSAXXnhh4Pn8+fO1SpUqev755+s333yja9as0VmzZukFF1ygVatW1Z9//jmw7M6dO7Vt27Zas2ZNfe2113ThwoWalpamEyZM0G7duunEiRPzjCUnJ0e7deumjRs31kmTJmlaWpp+9913OmrUqMAyXbt21Y4dO+rChQt1/vz5etFFF2mFChWOuvpo7NixeW5j2LBh2rJlSy1XrpxOnjz5iHljxozR6Ohoffzxx/XXX3/VpUuX6sSJE/Xmm28OLJOSkqKArlmzJtA2ZcoUFRH973//qytXrtTRo0drQkKCArpq1SpVPXz1UW4zZszQsmXL6rBhw3TBggWampqq06ZN0xtvvFEzMjJUVbVTp07atWtXXbRokS5YsEAvv/xyrVKlig4aNCjPfSwsa9as0cqVK+uNN96oixcv1o8//lhr1Kih9957b2CZ9PR0bd68uU6YMCHQ9umnn6qI6EMPPaTLly/Xjz/+WOPi4vShhx4KLPPQQw/pF198oStXrtSlS5fq66+/rpUrV9bbb789sMz69eu1WrVq2qtXL/3111917ty5mpSUpOeee27gSjdVd/VWxYoVdc+ePQXuT8T+n2Znqq78VHXy1ar/Kn/46qEXK6lOG6y6ZqZqTvYxVxOpCPHqI98/5I/3UdqSwuzZsxXQmTNnBtqWL1+uAwcO1Dp16mjZsmW1du3aOnDgQE1NTT3q9Xv37tVHH31U27RpozExMVqtWjXt3Lmzjhw5MvBhl5fdu3fr0KFDtXbt2hodHa2JiYn65JNPBuYvW7ZMzznnHK1QoYKeeuqp+tFHH+V5SWp+SWHhwoUKaHx8/FGXlaq6S067dOmisbGxWrlyZW3fvr0++uijRyzTvXv3wGWyhzz44INas2ZNrVChgl588cX67rvvhpQUVFVnzZqlPXr00EqVKmmFChW0RYsWescddwTiW7RokZ555pkaExOjDRs21Jdffll79OgR9qSgqvrDDz/omWeeqeXLl9datWrpfffdp1lZWYH5hy4Tfuutt4543bhx47RVq1Zavnx5bdq0qT711FNHvN9//etftUmTJoG/jY4dO+rIkSOPWLeq6s8//6zdu3cPXK77f//3f7pt27Yjlhk4cOARiTs/Efd/unmR6sy7VF+pfTgRPCeq43uoJo9RPZj/Zb/FSahJQfQkOiT9kJSUpPPn533z85IlS2jZsmURR2T88u2339K/f39SU1OJjY31O5xSbe3atbRr146FCxfSsGHDApeNiP/TjC1BRegWHG6v3sz1E7S8vkiL0BUFEflJVY95bs/6FEyx1a1bNx5++GHS0tLyvUzXFI3ffvuNUaNGHTMh+Cr7IKR96hLBEUXoqkGL/q4iaZ0zIvMu4yJkScEUazfffLPfIRg44p6PiKIKm35yiWDpe0FF6KK8InSDocnlEVFzKFJYUjDGlDx710PK/9zNZduCLsuOa+udHroOKtb2L74IZknBGFMyZO5zQ1emjHZDWQaK0MVDy2vd6aGap5X600PHUuKSgqpaPXdjIlShX9iiCutmu0SwbDwc3O3ay0TDqX1cImh0MURFbhXcSFOikkJ0dDT79u2jQoUKfodijMnDvn37CqdM+a7fvLuMx8DOoHFEap/uEkGL/hB7Sr4vN/krUUmhZs2arFu3joSEBGJjY+2IwZgIoars27ePdevWUatWrRNbycE9sPwjN4Rl+jeH2yvVhZY3QOuBxbYIXSQpUUnh0OAh69evz7MOjzHGP9HR0dSqVeuIQX6OSXNgzUx3emj5R7mK0F3hFaHrUeyL0EWSEpUUwCWG4/qjM8ZEnu3LXSJIGQt71h5uTzjbnR5q3q9EFaGLJCUuKRhjiqn9O4KK0M053F4l0RWgaz0QqjXxLbzSwpKCMcY/OVnw23SXCFZOhuwDrj26EjTr504P1esGUqbg9ZhCY0nBGFP0tixyiWDJO5CxyWsUN0hN60HQtC9EHz0Whwk/SwrGmKKRsRmWeEXotgSNMVG9eVARuvr+xWcASwrGmHDKOuCKzyWPhlVTcxWhG+CSQe3OdpdxBLGkYIwpXKqwaX5QETpv2FSJgsaXuquHrAhdxLKkYIwpHHvWwZL/uWSwfcnh9vh2LhG0vNaK0BUDlhSMMScuM8MVoUseDWu+zFWE7jp3eqjmaf7GaI6LJQVjzPFRhXXfuUSwfLwrPwEQVQ4aX+4SQWJPK0JXTFlSMMaEZtcqSPaK0O1KO9xeu7NLBM37Q2wN/+IzhcKSgjEmfwf3wLIPXMmJ9FmH2wNF6AbBKTYuekkS1qQgIj2BF4Eo4L+q+lSu+Q2A0UA1b5n7VHVqOGMyxhxDTjasnelOD62YEFSELhZO7WtF6Eq4sCUFEYkCXgYuANKBeSIyWVWDxsbjQWC8qr4iIq2AqUBiuGIyxhRg+zKXCFLGwt70w+0J3VwiaNYPyluxyZIunEcKnYFUVU0DEJFxQG8gOCkocOivrCqwPozxGGNy278Dlo5zp4c2zD3cXrWRK0LXaiBUa+xffKbIhTMpJABBNW9JB87ItcwjwOcichtQETg/jPEYYwCyM10RupRDRegOuvZylQ8XoUs424rQlVJ+dzQPAN5W1edF5ExgrIi0UT10sbMjIjcDNwM0aNDAhzCNKQE2/+ISwZJ3XB0iAAQaXuASwal9IdqGsi3twpkU1gHB1a3qeW3BhgA9AVT1BxGJAeKAzcELqerrwOsASUlJhTzytzElWMZmlwSSR8OWXw6312jh7jJudT1UrudffCbihDMpzAOaikgjXDLoD1yba5k1QA/gbRFpCcQAW8IYkzElX9YBSPvEjWW8ahpotmuPqe7uJbAidKYAYUsKqpolIkOB6bjLTd9U1WQRGQ7MV9XJwF3AKBEZhut0HqyqdiRgzPFShY3z3BHBsvdcBzJ4Reguc4mg8eVQtry/cZqIF9Y+Be+eg6m52h4Kmk4BuoYzBmNKtD3pkPI/11ewfenh9vj2LhG0uBYq1vIvPlPs+N3RbIw5XpkZkDrRHRWs/hJ3kA1UqOmK0LUaBDXb+xqiKb4sKRhTHKjCum+9InQfHFmErkkvlwgSL7IidOakWVIwJpLtTHMF6FLGuIJ0h9TuDK0HQ/NrrAidKVSWFIyJNAd2u6OB5NHu6OCQSgnQ6gZ3VHBKC//iMyWaJQVjIkFONqyZ4TqMV0yArH2uvWwsNL3CJYIGf7AidCbsLCkY46dtS10iSBkLe4Pu7ax3jksEza6yInSmSFlSMKao7dsOy8a500MbfzzcXrWxV4TuBitCZ3xjScGYopCdCb995hJB2pRcReiuDipCZ3cZG39ZUjAmnDYvdIlg6bu5itBdCK0HWhE6E3EsKRhT2H7f5IrQpYyGLYsOt1sROlMMhJQURKQL0ExVx4jIKUBFVV0T3tCMKUayDrjTQsmj8yhCN8ArQne6nR4yEe+YSUFEHsTVJ2oCjMFVMn0XODu8oRkT4VRdR3HyaNdxfEQRusu9InSXWRE6U6yEcqRwFdAB+BlAVdeJiF0jZ0qvPenuEtLk0bBj2eH2+NNcImh5ratDZEwxFEpSOKCqKiIKICLWK2ZKn8zfYYVXhG7NVxwuQlfLFaFrPQji2/kaojGFIZSkMEFEXgaqisgfcaOlvRXesIyJAJoD6UFF6DL3uvaoctCkt0sEiRdBGbtew5Qcx/xrVtWnReRi4CDQHnhCVaeFPTJj/LJzJSSPgSVjjyxCV+cMd/WQFaEzJVgoHc3/VNW/A9PyaDOmZAgUoXsb1n13uL1SPXeHcetBUKO5b+EZU1RCOe7tCeROAJfm0WZM8ZKT7foHkke7QWuOKEJ3pUsE9c+zInSmVMk3KYjILcCfgGYi8nPQrMp4VyIZUyxtW+ISwZL/5SpCd65LBM2ucuUnjCmFCjpSGA98BTwJ3BfUvkdVN+f9EmMi1L5tsHScu8t447zD7VUbu0TQ6gao2si/+IyJEPkmBVXdAewA+gGISA3cjWtlRaSuqq4vmhCNOUHZme7u4pTRsHIK5GS69nJVoPnVrtM4oavdZWxMkFA6mi8B/g3UA7YBdYEVgA39ZCLT5oWuw3jJu7Bvi2uTMl4RusFwam8rQmdMPkLpaP4nrszF56raQUQuAK4Ob1jGHKffN3pF6MbkKkLX0rvL+HqonOBffMYUE6EkhSxV3SIiZUREVPULEXku7JEZcyxZ+91poZTRsOqzoCJ0NaCFV4SuVpKdHjLmOISSFHaJSCXgO2CMiGwG9oU3LGPyoQob5rpEsHQcHNjp2suUhca9XCJodKkVoTPmBIWSFPrgksBfgYFAVeDycAZlzFF2r3V3GCePhh3LD7fX7OASQYsBVoTOmEIQSpmLPd5kNvCGiAiuT+H9cAZmDOCGrfxssDsqOKII3fVeEbq2fkZnTIlT0M1rlYA/AwnAZGAmcAtwD7AESwom3FTh8/+Dpe9ZETpjikhB/1n/A/YCPwC3Ag8A5YGrVXV+EcRmSrvZ/3DjFkRXhKu/htpJfkdkTIlXUFJooqptAUTkVWAj0EBVrZPZhN+i12HuE24Us8vGW0IwpoiUKWBe5qEJVc0G1lpCMEUi7VP48s9u+vxXoPEl/sZjTClSUFJoLyLbvccOoN2haRHZHsrKRaSniCwTkVQRuS+fZa4WkRQRSRaRd09kJ0wJsnE+TLnaDXDT5UFod5PfERlTqhR0+qjcyaxYRKKAl4ELgHRgnohMVtWUoGWaAvcDXVV1h4jYNYWl2c40mHgpZGVAq4Fw1nC/IzKm1CmoIF72Sa67M5CqqmkAIjIO6A2kBC1zE/CyV3wPq75aiu3bBhMuhozN0OB8uHCU3YlsjA8KOn10shKAtUHP0722YM1w4zXMFpE5ItIzrxWJyM0iMl9E5m/ZsiVM4RrfZO6DSb3cTWnx7aDXR+4SVGNMkQtnUghFWaAp0B0YAIwSkWq5F1LV11U1SVWT4uPjizhEE1Y52TDtBlj/vRv6su9UKF/F76iMKbVCSgoiUk9EzvOmy4tIxRBetg6oH/S8ntcWLB2YrKqZqroKWI5LEqa0+OZvsOIjKF8VrpxmlUyN8dkxk4KI3Ii7o/m/XlND4OMQ1j0PaCoijUSkHNDfW0+wSbijBEQkDnc6KS2kyE3x99O/4Od/Q5lo6DUR4tr4HZExpV4oRwq3A12A3QCquhw45lVCqpoFDAWm48pijFfVZBEZLiK9vMWmA9tEJAVXRuNuVd12/Lthip3lH8LXd7npnm9Dg/N8DccY44RSQGa/qh4U70oQ71LTkC4LUdWpwNRcbQ8FTStwp/cwpUX6dzD1ekDh7Ceh5bV+R2SM8YRypDBbRO4BYrx+hfeBT8Iblimxti2Fj3tD9gFo/2fofK/fERljgoSSFO4B9gBLgTuAr3DF8Yw5Pr9vdPci7N8OjS+HP4ywexGMiTChnD66FPivqr4S7mBMCXZwL0y8DHb/BrVPh8ves/LXxkSgUI4U+gGpIvKWV8soKtxBmRImJws+uQY2/QRVG0PfT1w5bGNMxDlmUlDVG3CXik4B/gikeaW0jTk2VfjyL7BqKsScAldMs2EzjYlgIR2/q+oBEfkYN1ZzFG44zj+FMzBTQsz9J/w6CsrGQN8pUKOZ3xEZYwoQys1rF4jIf4GVwHXAGKB2uAMzJUDyGJj9ICBwybtQ90y/IzLGHEMoRwo34y5Dvc0G2TEhW/0lfD7ETZ/3IjTt6288xpiQHDMpqGq/ogjElCCbf4HJV7gO5k53Qcfb/I7IGBOifJOCiHyjqud6o65p8Czczcg1wh6dKX52r4WJl8DBPdDsajj3Gb8jMsYch4KOFA4Vo4krikBMCbB/p0sIe9dDvXPg4tEgfldnN8Ycj3z/Y1U1x5t8Q1Wzgx/AG0UTnik2sg+6U0ZbF0ONFq7qadkYv6MyxhynUL7GtQt+4t28dnp4wjHFkipMvxHWzoSKtd29CLF2dtGY4ijfpCAi93r9Ce1EZLv32AFsIVflU1PKffcALHnH3aXc91Oomuh3RMaYE1TQkcIzQDzwL+9nPBCnqjVU9e6iCM4UA7+8Cj8+CRIFl38ItTr6HZEx5iQU1NF8qqquEJGxQOtDjYfGVVDVRWGOzUS6lVPgq1vd9AWvQaOe/sZjjDlpBSWF+4AhwMt5zFPgnLBEZIqHDT/CJ/1Bc6DLQ9B2iN8RGWMKQb5JQVWHeD8XxyAdAAAVrklEQVS7FV04pljYudKVwc7KgNaD4axH/I7IGFNIQql9dIWIVPam7xOR8SLSPvyhmYiUsdUNlLNvCzS8AC543QbKMaYECeWS1EdUdY+InAVcArwDvBbesExEytwHk3rBjhUQ3951LEdF+x2VMaYQhZIUsr2flwGvqerHQPnwhWQiUk42TL0ONvwAlevDFVOhfBW/ozLGFLJQqqRuEJGXgYuBTiJSjtCSiSkpVOHrOyF1IpSv6m5Oq1TX76iMMWEQyof71cA3wCWqugNXC+m+sEZlIstP/4IFIyCqHPSeBHGtj/0aY0yxFMpwnHuBZKC7iPwJqK6q08IemYkMy8bDN3e56Yvehvrd/YzGGBNmoVx9NBT4AGjgPcaLyF/CHZiJAOnfwrQb3HS3p6HlAH/jMcaEXagjr3X2jhgQkX8C3wP/CWdgxmfblsDHvV310/Z/gdOtsokxpUEofQoCHAx6num1mZJq7wZ3L8L+HdCkN/xhhN2LYEwpEcqRwlhgroh8hEsGfYDRYY3K+OfgXne38u7VUOcMuPRdKBPld1TGmCISyhjNz4jI18DZuJpHf1LVeeEOzPggOxOm9IPNP0O1JtBnCkRX8DsqY0wRCuVIAWA/cADI8X6akkYVvvwz/PYZxMbBFZ9BhXi/ozLGFLFQrj56AHgPqAPUA94VkftDWbmI9BSRZSKSKiL53tsgIleKiIpIUqiBm0I253FY/AaUjXVHCNVP9TsiY4wPQjlSGAh0UNUMABF5AlgAPFnQi7xhO18GLgDSgXkiMllVU3ItVxm4A5h7/OGbQrH4bfj+IZAycOl7ULeL3xEZY3wSytVHGzgyeZT12o6lM5CqqmmqehAYB/TOY7nHgKdxp6hMUfvtc/jiJjd93gg4Na9fkTGmtAglKWwHkkXkvyIyCvgV2CoiL4jICwW8LgFYG/Q83WsLEJGOQH1V/fQ44zaFYfNCmHIV5GRB0t3Q4Va/IzLG+CyU00efeo9D5hTGhkWkDPACMDiEZW/G3URHgwYNCmPzZvcamHAJHNwDzfvDOU/5HZExJgKEcknqGye47nVA/aDn9by2QyoDbYCvvXGfawOTRaSXqs7PFcPrwOsASUlJeoLxmEP273QJ4fcNUO9c6Pm2608wxpR64fwkmAc0FZFGXrnt/sDkQzNVdZeqxqlqoqom4o5AjkoIppBlHYDJfWFbMpzSCnpPhLI2PIYxxglbUlDVLGAoMB1YAoxX1WQRGS4ivcK1XVMAzYHpf4S1X0PFOm6gnJjqfkdljIkgod68hoiUV9XjunFNVacCU3O1PZTPst2PZ93mBHz7d1j6HkRXcgmhSkO/IzLGRJhQbl7rLCK/Aiu85+1F5KWwR2YK18L/wLynoUxZ6PUR1DzN74iMMREolNNHI3DjM28DUNVfgPPCGZQpZKmTYcZtbvqCUZB4ob/xGGMiVihJoYyqrs7Vlh2OYEwYbJgLn/Z3/QlnPgJtBvsdkTEmgoXSp7BWRDoD6pWuuA1YHt6wTKHYkQoTL4esfdDmRjgzz+4cY4wJCOVI4c/AnbihODcBXbw2E8kytriBcvZtgcSL4PxXbaAcY8wxhXLz2mbcPQamuMjMgEm9YGcq1OwAl38AUdF+R2WMKQaOmRS8ekdH3UWsqjeHJSJzcnKyYep1sGEOVG4AfT+FcpX9jsoYU0yE0qfwZdB0DNCXIwvdmUihCjP/CqmToHw1uPIzqFTH76iMMcVIKKeP3g9+LiJjge/CFpE5cfOfh4UjIaoc9PkYTmnpd0TGmGLmRMpcNAJqFXYg5iQtHQez7nbTPcdAvXP8jccYUyyF0qewg8N9CmVw4yvkO7Sm8cHab+CzQW76nGehxTX+xmOMKbYKTArialq353DJ6xxVtdLVkWRbCnzcB7IPQofbIOkuvyMyxhRjBZ4+8hLAVFXN9h6WECLJ3vXw0cVwYCec2he6/8vuRTDGnJRQ+hQWikiHsEdijs/BPTDhUtizBup0gUvegTJRfkdljCnm8j19JCJlvTEROgDzRGQl8DsguIOIjkUUo8ktOxOm9IMtC6F6U+gzBaJj/Y7KGFMCFNSn8CPQEbABcSKJKnxxC/w2HWLj4YppUCHO76iMMSVEQUlBAFR1ZRHFYkLxw3BIfgvKxkLfT6BaE78jMsaUIAUlhXgRuTO/mar6QhjiMQVZ/Bb88AhIGbh0HNTp7HdExpgSpqCkEAVUwjtiMD77bTp8fpOb/sNIONXO6hljCl9BSWGDqg4vskhM/jYtgMlXgWbD6ffCaVa53BgTHgVdkmpHCJFg92qYeClk7oUW10K3f/odkTGmBCsoKfQosihM3vbvcDen/b4B6neHi950/QnGGBMm+X7CqOr2ogzE5JJ1wJWv2L4ETmkNvSZC2fJ+R2WMKeHsa2ck0hxX4C59FlSq6+5FiKnmd1TGmFLAkkIkmnUfLHvfjZjWdypUqe93RMaYUsKSQqRZMBLmPwtlysLlH0HN9n5HZIwpRSwpRJIVk2DG7W76wv9C4gX+xmOMKXUsKUSK9XNg6gBA4azh0HqQ3xEZY0ohSwqRYMcKmHQ5ZO2Htv8HXR70OyJjTCllScFvGZthwsWwbys0uhjOf8UGyjHG+MaSgp8yM2Di5bBzJdTsCJeNdx3Mxhjjk7AmBRHpKSLLRCRVRO7LY/6dIpIiIotE5CsRaRjOeCJKTjZ8OgA2/ghVEuGKT6FcJb+jMsaUcmFLCiISBbwMXAy0AgaISKtciy0AklS1HfAh8Ey44okoqu4qo5WTIaa6uzmtYm2/ozLGmLAeKXQGUlU1TVUPAuOA3sELqOpMVc3wns4B6oUxnsgx71n45T8QVR56T4ZTWvgdkTHGAOFNCgnA2qDn6V5bfoYA0/KaISI3i8h8EZm/ZcuWQgzRB0veg2/vBQQuHgv1zvY7ImOMCYiIjmYRuR5IAp7Na76qvq6qSaqaFB8fX7TBFaa1X7uaRgDnPgfN+/kajjHG5BbOS13WAcFFe+p5bUcQkfOBB4BzVfVAGOPx19ZkV/U0JxM63gGdhvkdkTHGHCWcRwrzgKYi0khEygH9gcnBC4hIB+A1oJeqbg5jLP7au97di3BgFzS9As593u5FMMZEpLAlBVXNAoYC04ElwHhVTRaR4SJyaIDhZ3HjQH8gIgtFZHI+qyu+DuyGCZfAnrVQ9yy4+H9QJsrvqIwxJk9hvVNKVacCU3O1PRQ0fX44t++77EyYchVs+QWqN4PeH0N0rN9RGWNMviKio7lEUoUvboLVX0CFmu5ehApxfkdljDEFsqQQLt8/AsmjoWwF6PsJVGvsd0TGGHNMlhTC4dc3YM5wkDJw2ftQ+3S/IzLGmJBYUihsq6bBF7e46R7/gSaX+RuPMcYcB0sKhWnTzzClH2g2nPF3aH+L3xEZY8xxsaRQWHb9BhMvhczfoeX10PVxvyMyxpjjZkmhMOzb7m5O+30jNPgDXPSG3ZxmjCmWLCmcrKz9rnzF9qUQ1xZ6TYCocn5HZYwxJ8SSwsnQHJg2CNZ9C5US4IqpUL6q31EZY8wJs6RwMr65B5aPh3JVXEKoXDqGgzDGlFyWFE7UzyPgp+fdmMq9JkB8O78jMsaYk2ZJ4USsmAAz/+qmL3oTGvbwNx5jjCkklhSO17rvYep1gMLZT0CrG/yOyBhjCo0lheOxfTlM6uWuOGp3M3S+3++IjDGmUFlSCFXGZncvwv5t0PhS6PGy3YtgjClxLCmEIvN3mHgZ7EqDWklw6TjXwWyMMSWMJYVjycmCT/rDxnlQtZErg12ukt9RGWNMWFhSKIgqzLgN0j6BmBpuoJyKtfyOyhhjwsaSQkF+fBp+eRWiykOfyVCjud8RGWNMWFlSyM+Sd+C7+wGBS96BhK5+R2SMMWFnSSEva2bAZ390091fgGZX+huPMcYUEUsKuW1dDB/3hZxM6DQMOv3V74iMMabIWFIItmcdfHQxHNwNza6Cc5/zOyJjjClSlhQOObAbJl4Ce9Mh4Wy4eCyIvT3GmNLFPvUAsg/C5CthyyKo3hx6fwxlY/yOyhhjipwlBVX4/CZY8yVUqAVXToPYGn5HZYwxvrCk8P1DkDIGoiu6u5WrNvI7ImOM8U3pTgqLRsGcx0Gi4LLxUDvJ74iMMcZXpTcppE2FL//sps9/BRpf4m88xhgTAUpnUtj0E3xyNWg2dHkQ2t3kd0TGGBMRwpoURKSniCwTkVQRuS+P+eVF5H1v/lwRSQxnPADsWgUTLnXlsFsNhLOGh32TxhhTXIQtKYhIFPAycDHQChggIq1yLTYE2KGqpwL/Ap4OVzwA7Nvmbk7L2AQNzocLR9lAOcYYEyScRwqdgVRVTVPVg8A4oHeuZXoDo73pD4EeImH6lM7aD5N6w45lEN8Oen0IUeXCsiljjCmuwpkUEoC1Qc/TvbY8l1HVLGAXcEqhR6I5MO0GWD8bKtWDvlOhfNVC34wxxhR3xaKjWURuFpH5IjJ/y5YtJ7aSyg1cIrhyGlTOnZuMMcZAeJPCOqB+0PN6Xluey4hIWaAqsC33ilT1dVVNUtWk+Pj4449EykD352HQYohrc/yvN8aYUiKcSWEe0FREGolIOaA/MDnXMpOBQd70VcAMVdWwRVS5XthWbYwxJUHZcK1YVbNEZCgwHYgC3lTVZBEZDsxX1cnAG8BYEUkFtuMShzHGGJ+ELSkAqOpUYGqutoeCpvcD/cIZgzHGmNAVi45mY4wxRcOSgjHGmABLCsYYYwIsKRhjjAmwpGCMMSZAwnlbQDiIyBZg9Qm+PA7YWojhFAe2z6WD7XPpcDL73FBVj3n3b7FLCidDROaraqkaXs32uXSwfS4dimKf7fSRMcaYAEsKxhhjAkpbUnjd7wB8YPtcOtg+lw5h3+dS1adgjDGmYKXtSMEYY0wBSmRSEJGeIrJMRFJF5L485pcXkfe9+XNFJLHooyxcIezznSKSIiKLROQrEWnoR5yF6Vj7HLTclSKiIlLsr1QJZZ9F5Grvd50sIu8WdYyFLYS/7QYiMlNEFnh/35f4EWdhEZE3RWSziCzOZ76IyAjv/VgkIh0LNQBVLVEPXJnulUBjoBzwC9Aq1zJ/AV71pvsD7/sddxHs83lABW/6z6Vhn73lKgOzgDlAkt9xF8HvuSmwAKjuPa/pd9xFsM+vA3/2plsBv/kd90nu8zlAR2BxPvMvAaYBAnQB5hbm9kvikUJnIFVV01T1IDAO6J1rmd7AaG/6Q6CHiEgRxljYjrnPqjpTVTO8p3NwI+EVZ6H8ngEeA54G9hdlcGESyj7fBLysqjsAVHVzEcdY2ELZZwWqeNNVgfVFGF+hU9VZuPFl8tMbGKPOHKCaiNQprO2XxKSQAKwNep7uteW5jKpmAbuAU4okuvAIZZ+DDcF90yjOjrnP3mF1fVX9tCgDC6NQfs/NgGYiMltE5ohIzyKLLjxC2edHgOtFJB03fsttRROab473//24hHWQHRN5ROR6IAk41+9YwklEygAvAIN9DqWolcWdQuqOOxqcJSJtVXWnr1GF1wDgbVV9XkTOxI3m2EZVc/wOrDgqiUcK64D6Qc/reW15LiMiZXGHnNuKJLrwCGWfEZHzgQeAXqp6oIhiC5dj7XNloA3wtYj8hjv3OrmYdzaH8ntOByaraqaqrgKW45JEcRXKPg8BxgOo6g9ADK5GUEkV0v/7iSqJSWEe0FREGolIOVxH8uRcy0wGBnnTVwEz1OvBKaaOuc8i0gF4DZcQivt5ZjjGPqvqLlWNU9VEVU3E9aP0UtX5/oRbKEL5256EO0pAROJwp5PSijLIQhbKPq8BegCISEtcUthSpFEWrcnAQO8qpC7ALlXdUFgrL3Gnj1Q1S0SGAtNxVy68qarJIjIcmK+qk4E3cIeYqbgOnf7+RXzyQtznZ4FKwAden/oaVe3lW9AnKcR9LlFC3OfpwIUikgJkA3erarE9Cg5xn+8CRonIMFyn8+Di/CVPRN7DJfY4r5/kYSAaQFVfxfWbXAKkAhnAHwt1+8X4vTPGGFPISuLpI2OMMSfIkoIxxpgASwrGGGMCLCkYY4wJsKRgjDEmwJKCiTgiki0iC4MeiQUsm5hfNcmiJiJJIjLCm+4uImcFzfuTiAwshG08IiLrvPclRUQGhPCaPiLS6mS3bUqHEnefgikR9qnqaX4Hcby8G+MO3RzXHdgLfO/Ne7UQN/UvVX1ORJoCP4nIh6qaWcDyfYBPgJRCjMGUUHakYIoF74jgWxH52XuclccyrUXkR+9b9CLvQxMRuT6o/TURicrjtb+JyDMi8qu37KlB250hh8ehaOC19xORxSLyi4jM8tq6i8gn3pHNn4Bh3ja7ed/w/yYiLUTkx1z79as33UlEvhGRn0Rk+rEqX6rqCtzNS9W9198kIvO8mD4SkQre+9QLeNaLpYn3+Mzbzrci0uL4fyOmpLKkYCJRbNCpo4le22bgAlXtCFwDjMjjdX8CXvSOMpKAdK/swTVAV689G7gun+3uUtW2wEjg317bS8BoVW0HvBO03YeAi1S1Pe5DN0BVfwNexX2jP01Vvw2atxQoJyKNvKZrgPdFJNrb1lWq2gl4E3iioDdJXBXYFUFlSyao6uleTEuAIar6Pa4swt1eLCtx4w/c5m3nb8B/CtqOKV3s9JGJRHmdPooGRorIoQ/2Znm87gfgARGph/uAXCEiPYBOwDyvvEcsLsHk5b2gn//yps8ErvCmxwLPeNOzgbdFZDww4Xh2Dle87RrgKe/nNUBzXAG/L7w4o4D86tkME5E/4t6Dy4Pa24jI40A1XEmT6blfKCKVgLM4XO4EoPxxxm9KMEsKprgYBmwC2uOOcI8aNEdV3xWRucClwFQRuQU3OtVoVb0/hG1oPtNHL6j6JxE5w9vWTyLSKbTdAOB93IfyBLcqXSEibYFkVT0zhNcf6lPoBbwhIk1UdT/wNtBHVX8RkcF4hfFyKQPsLI59NqZo2OkjU1xUBTZ4NfJvwH2TPoKINAbSVHUE8DHQDvgKuEpEanrL1JD8x6e+JujnD9709xwumHgd8K23niaqOldVH8JV5AwuZQywB1e++yjeKZxs4B+4BAGwDIgXNx4AIhItIq3zifPQeibjOrYPVfytDGzwTkUFnyILxKKqu4FVItLP246ISPuCtmNKF0sKprj4DzBIRH4BWgC/57HM1cBiEVmIOxUzRlVTgAeBz0VkEfAFkF8HbnVvmTtwRybgRvH6o9d+gzcPXMftr97lsN/jxg4ONgXoe6ijOY9tvQ9cz+FxAA7iyrg/7e3jQtxpnmMZDtwpblChfwBzcae2lgYtMw64W9zA9k1wCWOIt51k8h7G1JRSViXVGNzVR0CSqm71OxZj/GRHCsYYYwLsSMEYY0yAHSkYY4wJsKRgjDEmwJKCMcaYAEsKxhhjAiwpGGOMCbCkYIwxJuD/AV241eudStoHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import json\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from plotLayer import *\n",
    "from preprocess import *\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy import sparse as sp\n",
    "from skimage.measure import block_reduce\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, classification_report, precision_recall_curve\n",
    "\n",
    "from model import *\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "\n",
    "def Classify_Rate(y, y_hat):\n",
    "    # True Positive (TP): we predict a label of 1 (positive), and the true label is 1.\n",
    "    TP = np.sum(np.logical_and(y_hat == 1, y == 1))\n",
    "    # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n",
    "    TN = np.sum(np.logical_and(y_hat == 0, y == 0))\n",
    "    # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n",
    "    FP = np.sum(np.logical_and(y_hat == 1, y == 0))\n",
    "    # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n",
    "    FN = np.sum(np.logical_and(y_hat == 0, y == 1))\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "\n",
    "def Predict(model, x, y_threshold=None):\n",
    "    y_hat = model.predict(x)\n",
    "\n",
    "    if y_threshold :\n",
    "        y_hat[y_hat < y_threshold] = 0\n",
    "        y_hat[y_hat >= y_threshold] = 1\n",
    "    return y_hat\n",
    "\n",
    "def PlotROC(y, y_hat):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(2):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y, y_hat)\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    print (\"roc_auc_score:%f\" %roc_auc_score(y, y_hat))\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[1], tpr[1])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.show()\n",
    "\n",
    "def PreprocessData(datapath, width=256, channel=6):\n",
    "    ratio = 1024 // width\n",
    "    with open(datapath, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    x = np.heaviside(np.array([map(lambda x: block_reduce(x.toarray(), block_size=(ratio,ratio), func=np.max), d.hL) for d in data]), 0)\n",
    "    x = np.swapaxes(x, 1, 3)\n",
    "    y = np.array([d.label for d in data])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    width = 256\n",
    "    channel = 6\n",
    "    #classify_weights_path = \"Classify_epoch_50_batch_4.hdf5\"\n",
    "    classify_weights_path = \"Baseline_Classify_epoch_100_batch_4.hdf5\"\n",
    "\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "    sess = tf.Session(config=config)\n",
    "    set_session(sess)\n",
    "\n",
    "    classify_model = Encoder_Classify(input_size=(width,width,6), batch_normal=True)\n",
    "    classify_model.load_weights(classify_weights_path)\n",
    "\n",
    "    d0_path = \"../Data/1stDataset/d0*\"\n",
    "    false_path = \"../Data/1stDataset/false*\"\n",
    "    d0 = np.sort(glob.glob(d0_path))\n",
    "    f0 = np.sort(glob.glob(false_path))\n",
    "\n",
    "    y_total = []\n",
    "    y_hat_total = []\n",
    "#     301\n",
    "    for i in range(500,601):\n",
    "        x1, y1 = PreprocessData(d0[i], width=width, channel=channel)\n",
    "        x2, y2 = PreprocessData(f0[i], width=width, channel=channel)\n",
    "        x = np.concatenate((x1, x2), axis=0)\n",
    "        y = np.concatenate((y1, y2), axis=0)\n",
    "\n",
    "        y_hat = Predict(classify_model, x)\n",
    "        y_total += [y]\n",
    "        y_hat_total += [y_hat]\n",
    "        print(\"y_hat mean:%f median:%f\" %(np.mean(y_hat), np.median(y_hat)))\n",
    "        y_hat[y_hat < np.median(y_hat)] = 0\n",
    "        y_hat[y_hat >= np.median(y_hat)] = 1\n",
    "\n",
    "        TP, TN, FP, FN = Classify_Rate(y, y_hat)\n",
    "        print(\"Sensitive TP/(TP+FN) : %f\" %(TP / (TP + FN)))\n",
    "        print(classification_report(y, y_hat))\n",
    "\n",
    "    y = np.concatenate(y_total)\n",
    "    y_hat = np.concatenate(y_hat_total)\n",
    "    a=np.hstack((y,y_hat))\n",
    "    np.savetxt(\"baseline_y_y_hat.txt\",a,delimiter=',')\n",
    "    print(y.shape)\n",
    "    print(y_hat.shape)\n",
    "    print(\"y_hat mean:%f median:%f\" %(np.mean(y_hat), np.median(y_hat)))\n",
    "    fp,tp,tr=roc_curve(y,y_hat)\n",
    "    p,r,tr1=precision_recall_curve(y,y_hat)\n",
    "    plt.figure(1)\n",
    "    plt.plot(fp,tp,color='darkorange',lw=2,label='ROC curve(area = %0.3f)'%auc(fp,tp))\n",
    "    plt.xlabel('False positive Rate')\n",
    "    plt.ylabel('True positive Rate')\n",
    "    legend = plt.legend(fontsize = 'x-large')\n",
    "    plt.savefig('ROC_curve_baseline.png')\n",
    "    plt.show()\n",
    "    plt.figure(2)\n",
    "    plt.plot(r,p,color='darkorange', label='Precision recall curve') \n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    legend=plt.legend(fontsize='x-large')\n",
    "    plt.savefig('Precision_Recall_baseline.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC curve area = 0.636"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitive TP/(TP+FN) : 0.636238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64     10100\n",
      "           1       0.64      0.64      0.64     10100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64     20200\n",
      "   macro avg       0.64      0.64      0.64     20200\n",
      "weighted avg       0.64      0.64      0.64     20200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    y_hat[y_hat < np.median(y_hat)] = 0\n",
    "    y_hat[y_hat >= np.median(y_hat)] = 1\n",
    "    TP, TN, FP, FN = Classify_Rate(y, y_hat)\n",
    "    print(\"Sensitive TP/(TP+FN) : %f\" %(TP / (TP + FN)))\n",
    "    print(classification_report(y, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
