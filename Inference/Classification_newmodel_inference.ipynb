{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 256, 256, 6)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 256, 256, 64)      3520      \n",
      "_________________________________________________________________\n",
      "batch_normalization_103 (Bat (None, 256, 256, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_104 (Bat (None, 256, 256, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_105 (Bat (None, 128, 128, 128)     512       \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_106 (Bat (None, 128, 128, 128)     512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_107 (Bat (None, 64, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_108 (Bat (None, 64, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_109 (Bat (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_110 (Bat (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 16, 16, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "batch_normalization_111 (Bat (None, 16, 16, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 16, 16, 1024)      9438208   \n",
      "_________________________________________________________________\n",
      "batch_normalization_112 (Bat (None, 16, 16, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 8, 8, 512)         4719104   \n",
      "_________________________________________________________________\n",
      "batch_normalization_113 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_114 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 4, 4, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_115 (Bat (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_116 (Bat (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_117 (Bat (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_118 (Bat (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "batch_normalization_119 (Bat (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 65,511,681\n",
      "Trainable params: 65,482,241\n",
      "Non-trainable params: 29,440\n",
      "_________________________________________________________________\n",
      "y_hat mean:0.085691 median:0.034936\n",
      "Sensitive TP/(TP+FN) : 0.610000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       100\n",
      "           1       0.61      0.61      0.61       100\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       200\n",
      "   macro avg       0.61      0.61      0.61       200\n",
      "weighted avg       0.61      0.61      0.61       200\n",
      "\n",
      "y_hat mean:0.098667 median:0.034442\n",
      "Sensitive TP/(TP+FN) : 0.600000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60       100\n",
      "           1       0.60      0.60      0.60       100\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       200\n",
      "   macro avg       0.60      0.60      0.60       200\n",
      "weighted avg       0.60      0.60      0.60       200\n",
      "\n",
      "y_hat mean:0.080338 median:0.029395\n",
      "Sensitive TP/(TP+FN) : 0.650000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       100\n",
      "           1       0.65      0.65      0.65       100\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.65      0.65      0.65       200\n",
      "\n",
      "y_hat mean:0.087523 median:0.029820\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "y_hat mean:0.092593 median:0.028170\n",
      "Sensitive TP/(TP+FN) : 0.700000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70       100\n",
      "           1       0.70      0.70      0.70       100\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       200\n",
      "   macro avg       0.70      0.70      0.70       200\n",
      "weighted avg       0.70      0.70      0.70       200\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat mean:0.081879 median:0.024828\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "y_hat mean:0.086275 median:0.033313\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.077396 median:0.028229\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.087645 median:0.031138\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.071622 median:0.030641\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.087034 median:0.025427\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "y_hat mean:0.078362 median:0.026817\n",
      "Sensitive TP/(TP+FN) : 0.650000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       100\n",
      "           1       0.65      0.65      0.65       100\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.65      0.65      0.65       200\n",
      "\n",
      "y_hat mean:0.078177 median:0.035523\n",
      "Sensitive TP/(TP+FN) : 0.650000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       100\n",
      "           1       0.65      0.65      0.65       100\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.65      0.65      0.65       200\n",
      "\n",
      "y_hat mean:0.089191 median:0.027644\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "y_hat mean:0.080620 median:0.031661\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.088797 median:0.025582\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.095501 median:0.035884\n",
      "Sensitive TP/(TP+FN) : 0.680000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68       100\n",
      "           1       0.68      0.68      0.68       100\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       200\n",
      "   macro avg       0.68      0.68      0.68       200\n",
      "weighted avg       0.68      0.68      0.68       200\n",
      "\n",
      "y_hat mean:0.085158 median:0.027695\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.085277 median:0.031916\n",
      "Sensitive TP/(TP+FN) : 0.680000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68       100\n",
      "           1       0.68      0.68      0.68       100\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       200\n",
      "   macro avg       0.68      0.68      0.68       200\n",
      "weighted avg       0.68      0.68      0.68       200\n",
      "\n",
      "y_hat mean:0.068947 median:0.027640\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "y_hat mean:0.069195 median:0.027639\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.088241 median:0.034708\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.083934 median:0.027790\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.083878 median:0.029863\n",
      "Sensitive TP/(TP+FN) : 0.710000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71       100\n",
      "           1       0.71      0.71      0.71       100\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       200\n",
      "   macro avg       0.71      0.71      0.71       200\n",
      "weighted avg       0.71      0.71      0.71       200\n",
      "\n",
      "y_hat mean:0.074654 median:0.030315\n",
      "Sensitive TP/(TP+FN) : 0.710000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71       100\n",
      "           1       0.71      0.71      0.71       100\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       200\n",
      "   macro avg       0.71      0.71      0.71       200\n",
      "weighted avg       0.71      0.71      0.71       200\n",
      "\n",
      "y_hat mean:0.064228 median:0.024826\n",
      "Sensitive TP/(TP+FN) : 0.690000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       100\n",
      "           1       0.69      0.69      0.69       100\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       200\n",
      "   macro avg       0.69      0.69      0.69       200\n",
      "weighted avg       0.69      0.69      0.69       200\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat mean:0.087927 median:0.025086\n",
      "Sensitive TP/(TP+FN) : 0.670000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67       100\n",
      "           1       0.67      0.67      0.67       100\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.67      0.67      0.67       200\n",
      "\n",
      "y_hat mean:0.089262 median:0.029138\n",
      "Sensitive TP/(TP+FN) : 0.610000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       100\n",
      "           1       0.61      0.61      0.61       100\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       200\n",
      "   macro avg       0.61      0.61      0.61       200\n",
      "weighted avg       0.61      0.61      0.61       200\n",
      "\n",
      "y_hat mean:0.071535 median:0.027930\n",
      "Sensitive TP/(TP+FN) : 0.680000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68       100\n",
      "           1       0.68      0.68      0.68       100\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       200\n",
      "   macro avg       0.68      0.68      0.68       200\n",
      "weighted avg       0.68      0.68      0.68       200\n",
      "\n",
      "y_hat mean:0.079776 median:0.033047\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "y_hat mean:0.083738 median:0.031613\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.079335 median:0.030103\n",
      "Sensitive TP/(TP+FN) : 0.670000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67       100\n",
      "           1       0.67      0.67      0.67       100\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.67      0.67      0.67       200\n",
      "\n",
      "y_hat mean:0.077991 median:0.026629\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.087425 median:0.030322\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.084956 median:0.037097\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.072982 median:0.032285\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.086000 median:0.028865\n",
      "Sensitive TP/(TP+FN) : 0.680000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68       100\n",
      "           1       0.68      0.68      0.68       100\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       200\n",
      "   macro avg       0.68      0.68      0.68       200\n",
      "weighted avg       0.68      0.68      0.68       200\n",
      "\n",
      "y_hat mean:0.082190 median:0.029280\n",
      "Sensitive TP/(TP+FN) : 0.590000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59       100\n",
      "           1       0.59      0.59      0.59       100\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       200\n",
      "   macro avg       0.59      0.59      0.59       200\n",
      "weighted avg       0.59      0.59      0.59       200\n",
      "\n",
      "y_hat mean:0.078974 median:0.027081\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "y_hat mean:0.085294 median:0.026569\n",
      "Sensitive TP/(TP+FN) : 0.690000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       100\n",
      "           1       0.69      0.69      0.69       100\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       200\n",
      "   macro avg       0.69      0.69      0.69       200\n",
      "weighted avg       0.69      0.69      0.69       200\n",
      "\n",
      "y_hat mean:0.079955 median:0.031376\n",
      "Sensitive TP/(TP+FN) : 0.700000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70       100\n",
      "           1       0.70      0.70      0.70       100\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       200\n",
      "   macro avg       0.70      0.70      0.70       200\n",
      "weighted avg       0.70      0.70      0.70       200\n",
      "\n",
      "y_hat mean:0.084194 median:0.029119\n",
      "Sensitive TP/(TP+FN) : 0.720000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.72      0.72       100\n",
      "           1       0.72      0.72      0.72       100\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       200\n",
      "   macro avg       0.72      0.72      0.72       200\n",
      "weighted avg       0.72      0.72      0.72       200\n",
      "\n",
      "y_hat mean:0.084450 median:0.027471\n",
      "Sensitive TP/(TP+FN) : 0.680000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68       100\n",
      "           1       0.68      0.68      0.68       100\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       200\n",
      "   macro avg       0.68      0.68      0.68       200\n",
      "weighted avg       0.68      0.68      0.68       200\n",
      "\n",
      "y_hat mean:0.075572 median:0.033023\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.078978 median:0.028486\n",
      "Sensitive TP/(TP+FN) : 0.680000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68       100\n",
      "           1       0.68      0.68      0.68       100\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       200\n",
      "   macro avg       0.68      0.68      0.68       200\n",
      "weighted avg       0.68      0.68      0.68       200\n",
      "\n",
      "y_hat mean:0.078787 median:0.024797\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.085212 median:0.027234\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat mean:0.084363 median:0.029533\n",
      "Sensitive TP/(TP+FN) : 0.690000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       100\n",
      "           1       0.69      0.69      0.69       100\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       200\n",
      "   macro avg       0.69      0.69      0.69       200\n",
      "weighted avg       0.69      0.69      0.69       200\n",
      "\n",
      "y_hat mean:0.091872 median:0.034089\n",
      "Sensitive TP/(TP+FN) : 0.610000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       100\n",
      "           1       0.61      0.61      0.61       100\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       200\n",
      "   macro avg       0.61      0.61      0.61       200\n",
      "weighted avg       0.61      0.61      0.61       200\n",
      "\n",
      "y_hat mean:0.067754 median:0.026815\n",
      "Sensitive TP/(TP+FN) : 0.700000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70       100\n",
      "           1       0.70      0.70      0.70       100\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       200\n",
      "   macro avg       0.70      0.70      0.70       200\n",
      "weighted avg       0.70      0.70      0.70       200\n",
      "\n",
      "y_hat mean:0.080841 median:0.028642\n",
      "Sensitive TP/(TP+FN) : 0.680000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68       100\n",
      "           1       0.68      0.68      0.68       100\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       200\n",
      "   macro avg       0.68      0.68      0.68       200\n",
      "weighted avg       0.68      0.68      0.68       200\n",
      "\n",
      "(10200, 1)\n",
      "(10200, 1)\n",
      "y_hat mean:0.500000 median:0.500000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import json\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from plotLayer import *\n",
    "from preprocess import *\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy import sparse as sp\n",
    "from skimage.measure import block_reduce\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, classification_report, precision_recall_curve\n",
    "\n",
    "from model import *\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "\n",
    "def Classify_Rate(y, y_hat):\n",
    "    # True Positive (TP): we predict a label of 1 (positive), and the true label is 1.\n",
    "    TP = np.sum(np.logical_and(y_hat == 1, y == 1))\n",
    "    # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n",
    "    TN = np.sum(np.logical_and(y_hat == 0, y == 0))\n",
    "    # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n",
    "    FP = np.sum(np.logical_and(y_hat == 1, y == 0))\n",
    "    # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n",
    "    FN = np.sum(np.logical_and(y_hat == 0, y == 1))\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "\n",
    "def Predict(model, x, y_threshold=None):\n",
    "    y_hat = model.predict(x)\n",
    "\n",
    "    if y_threshold :\n",
    "        y_hat[y_hat < y_threshold] = 0\n",
    "        y_hat[y_hat >= y_threshold] = 1\n",
    "    return y_hat\n",
    "\n",
    "def PlotROC(y, y_hat):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(2):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y, y_hat)\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    print (\"roc_auc_score:%f\" %roc_auc_score(y, y_hat))\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[1], tpr[1])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.show()\n",
    "\n",
    "def PreprocessData(datapath, width=256, channel=6):\n",
    "    ratio = 1024 // width\n",
    "    with open(datapath, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    x = np.heaviside(np.array([map(lambda x: block_reduce(x.toarray(), block_size=(ratio,ratio), func=np.max), d.hL) for d in data]), 0)\n",
    "    x = np.swapaxes(x, 1, 3)\n",
    "    y = np.array([d.label for d in data])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    width = 256\n",
    "    channel = 6\n",
    "    #classify_weights_path = \"Classify_epoch_50_batch_4.hdf5\" the below model is copied one directory above\n",
    "    classify_weights_path = \"Newmodel_Classify_epoch_50_batch_5.hdf5\"\n",
    "\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "    sess = tf.Session(config=config)\n",
    "    set_session(sess)\n",
    "\n",
    "    classify_model = Encoder_Classify(input_size=(width,width,6), batch_normal=True)\n",
    "    classify_model.load_weights(classify_weights_path)\n",
    "\n",
    "    d0_path = \"../Data/1stDataset/d0*\"\n",
    "    false_path = \"../Data/1stDataset/false*\"\n",
    "    d0 = np.sort(glob.glob(d0_path))\n",
    "    f0 = np.sort(glob.glob(false_path))\n",
    "\n",
    "    y_total = []\n",
    "    y_hat_total = []\n",
    "    #proba is a keyword used in sklearn for probabilities\n",
    "    proba = []\n",
    "#     301\n",
    "    for i in range(500,551):\n",
    "        x1, y1 = PreprocessData(d0[i], width=width, channel=channel)\n",
    "        x2, y2 = PreprocessData(f0[i], width=width, channel=channel)\n",
    "        x = np.concatenate((x1, x2), axis=0)\n",
    "        y = np.concatenate((y1, y2), axis=0)\n",
    "\n",
    "        y_hat = Predict(classify_model, x)\n",
    "#         print(y_hat)\n",
    "        y_total += [y]\n",
    "        y_hat_total += [y_hat]\n",
    "        proba += [y_hat.copy()]\n",
    "# print(proba)-------You should be very careful in numpy as numpy arrays as get cop\n",
    "# https://jakevdp.github.io/PythonDataScienceHandbook/02.02-the-basics-of-numpy-arrays.html\n",
    "# Check the section sub arrays as no copy views\n",
    "        print(\"y_hat mean:%f median:%f\" %(np.mean(y_hat), np.median(y_hat)))\n",
    "        y_hat[y_hat < np.median(y_hat)] = 0\n",
    "        y_hat[y_hat >= np.median(y_hat)] = 1\n",
    "\n",
    "        TP, TN, FP, FN = Classify_Rate(y, y_hat)\n",
    "        print(\"Sensitive TP/(TP+FN) : %f\" %(TP / (TP + FN)))\n",
    "        print(classification_report(y, y_hat))\n",
    "\n",
    "    y = np.concatenate(y_total)\n",
    "    y_hat = np.concatenate(y_hat_total)\n",
    "    proba = np.concatenate(proba)\n",
    "    a=np.hstack((y,proba))\n",
    "    np.savetxt(\"newmodel_y_y_hat.txt\",a,delimiter=',')\n",
    "    print(y.shape)\n",
    "    print(y_hat.shape)\n",
    "    print(\"y_hat mean:%f median:%f\" %(np.mean(y_hat), np.median(y_hat)))\n",
    "    fp,tp,tr=roc_curve(y,proba)\n",
    "    p,r,tr1=precision_recall_curve(y,proba)\n",
    "    plt.figure(1)\n",
    "    plt.plot(fp,tp,color='darkorange',lw=2,label='ROC curve(area = %0.3f)'%auc(fp,tp))\n",
    "    plt.xlabel('False positive Rate')\n",
    "    plt.ylabel('True positive Rate')\n",
    "    legend = plt.legend(fontsize = 'x-large')\n",
    "    plt.savefig('ROC_curve_newmodel.png')\n",
    "    plt.show()\n",
    "    plt.figure(2)\n",
    "    plt.plot(r,p,color='darkorange', label='Precision recall curve') \n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    legend=plt.legend(fontsize='x-large')\n",
    "    plt.savefig('Precision_Recall_newmodel.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC curve area = 0.708"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitive TP/(TP+FN) : 0.655098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66      5100\n",
      "           1       0.66      0.66      0.66      5100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66     10200\n",
      "   macro avg       0.66      0.66      0.66     10200\n",
      "weighted avg       0.66      0.66      0.66     10200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    y_hat[y_hat < np.median(y_hat)] = 0\n",
    "    y_hat[y_hat >= np.median(y_hat)] = 1\n",
    "    TP, TN, FP, FN = Classify_Rate(y, y_hat)\n",
    "    print(\"Sensitive TP/(TP+FN) : %f\" %(TP / (TP + FN)))\n",
    "    print(classification_report(y, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(proba)\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [0.8, 0.9, 0.85, 0]).ravel()\n",
    "# What ever I have presented yesterday those contain thresholded values. \n",
    "# from sklearn.metrics import classification_report\n",
    "# y_true=np.array([0,1,1,1,0,0,1])\n",
    "# y_pred=np.array([0.3,0.9,0.8,0.3,0.2,0.3,0.8])\n",
    "# print(classification_report(y_true, y_pred))\n",
    "#Classification report as well as the confusion_matrix works only for a particular case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
