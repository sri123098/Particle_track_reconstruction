{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 256, 256, 6)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 256, 256, 64)      3520      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 256, 256, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 256, 256, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 128, 128, 128)     512       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 128, 128, 128)     512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 64, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 64, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 16, 16, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 16, 16, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 16, 16, 1024)      9438208   \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 16, 16, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 8, 8, 512)         4719104   \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 4, 4, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 65,511,681\n",
      "Trainable params: 65,482,241\n",
      "Non-trainable params: 29,440\n",
      "_________________________________________________________________\n",
      "y_hat mean:0.275551 median:0.251014\n",
      "Sensitive TP/(TP+FN) : 0.590000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59       100\n",
      "           1       0.59      0.59      0.59       100\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       200\n",
      "   macro avg       0.59      0.59      0.59       200\n",
      "weighted avg       0.59      0.59      0.59       200\n",
      "\n",
      "y_hat mean:0.279528 median:0.247089\n",
      "Sensitive TP/(TP+FN) : 0.580000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58       100\n",
      "           1       0.58      0.58      0.58       100\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       200\n",
      "   macro avg       0.58      0.58      0.58       200\n",
      "weighted avg       0.58      0.58      0.58       200\n",
      "\n",
      "y_hat mean:0.253490 median:0.200003\n",
      "Sensitive TP/(TP+FN) : 0.590000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59       100\n",
      "           1       0.59      0.59      0.59       100\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       200\n",
      "   macro avg       0.59      0.59      0.59       200\n",
      "weighted avg       0.59      0.59      0.59       200\n",
      "\n",
      "y_hat mean:0.281412 median:0.257304\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.269237 median:0.221511\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat mean:0.244987 median:0.206040\n",
      "Sensitive TP/(TP+FN) : 0.600000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60       100\n",
      "           1       0.60      0.60      0.60       100\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       200\n",
      "   macro avg       0.60      0.60      0.60       200\n",
      "weighted avg       0.60      0.60      0.60       200\n",
      "\n",
      "y_hat mean:0.265588 median:0.246752\n",
      "Sensitive TP/(TP+FN) : 0.590000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59       100\n",
      "           1       0.59      0.59      0.59       100\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       200\n",
      "   macro avg       0.59      0.59      0.59       200\n",
      "weighted avg       0.59      0.59      0.59       200\n",
      "\n",
      "y_hat mean:0.243653 median:0.208644\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.254069 median:0.236925\n",
      "Sensitive TP/(TP+FN) : 0.610000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       100\n",
      "           1       0.61      0.61      0.61       100\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       200\n",
      "   macro avg       0.61      0.61      0.61       200\n",
      "weighted avg       0.61      0.61      0.61       200\n",
      "\n",
      "y_hat mean:0.277588 median:0.277291\n",
      "Sensitive TP/(TP+FN) : 0.650000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       100\n",
      "           1       0.65      0.65      0.65       100\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.65      0.65      0.65       200\n",
      "\n",
      "y_hat mean:0.253585 median:0.212764\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.260527 median:0.224493\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.274748 median:0.253469\n",
      "Sensitive TP/(TP+FN) : 0.590000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59       100\n",
      "           1       0.59      0.59      0.59       100\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       200\n",
      "   macro avg       0.59      0.59      0.59       200\n",
      "weighted avg       0.59      0.59      0.59       200\n",
      "\n",
      "y_hat mean:0.254862 median:0.198986\n",
      "Sensitive TP/(TP+FN) : 0.680000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68       100\n",
      "           1       0.68      0.68      0.68       100\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       200\n",
      "   macro avg       0.68      0.68      0.68       200\n",
      "weighted avg       0.68      0.68      0.68       200\n",
      "\n",
      "y_hat mean:0.249010 median:0.223106\n",
      "Sensitive TP/(TP+FN) : 0.610000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       100\n",
      "           1       0.61      0.61      0.61       100\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       200\n",
      "   macro avg       0.61      0.61      0.61       200\n",
      "weighted avg       0.61      0.61      0.61       200\n",
      "\n",
      "y_hat mean:0.271410 median:0.239659\n",
      "Sensitive TP/(TP+FN) : 0.650000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       100\n",
      "           1       0.65      0.65      0.65       100\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.65      0.65      0.65       200\n",
      "\n",
      "y_hat mean:0.268886 median:0.236673\n",
      "Sensitive TP/(TP+FN) : 0.580000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58       100\n",
      "           1       0.58      0.58      0.58       100\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       200\n",
      "   macro avg       0.58      0.58      0.58       200\n",
      "weighted avg       0.58      0.58      0.58       200\n",
      "\n",
      "y_hat mean:0.259145 median:0.228996\n",
      "Sensitive TP/(TP+FN) : 0.580000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58       100\n",
      "           1       0.58      0.58      0.58       100\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       200\n",
      "   macro avg       0.58      0.58      0.58       200\n",
      "weighted avg       0.58      0.58      0.58       200\n",
      "\n",
      "y_hat mean:0.273292 median:0.240729\n",
      "Sensitive TP/(TP+FN) : 0.670000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67       100\n",
      "           1       0.67      0.67      0.67       100\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.67      0.67      0.67       200\n",
      "\n",
      "y_hat mean:0.263696 median:0.233341\n",
      "Sensitive TP/(TP+FN) : 0.610000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       100\n",
      "           1       0.61      0.61      0.61       100\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       200\n",
      "   macro avg       0.61      0.61      0.61       200\n",
      "weighted avg       0.61      0.61      0.61       200\n",
      "\n",
      "y_hat mean:0.256926 median:0.201224\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.275521 median:0.236133\n",
      "Sensitive TP/(TP+FN) : 0.570000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.57      0.57       100\n",
      "           1       0.57      0.57      0.57       100\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       200\n",
      "   macro avg       0.57      0.57      0.57       200\n",
      "weighted avg       0.57      0.57      0.57       200\n",
      "\n",
      "y_hat mean:0.236570 median:0.200474\n",
      "Sensitive TP/(TP+FN) : 0.590000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59       100\n",
      "           1       0.59      0.59      0.59       100\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       200\n",
      "   macro avg       0.59      0.59      0.59       200\n",
      "weighted avg       0.59      0.59      0.59       200\n",
      "\n",
      "y_hat mean:0.255860 median:0.202748\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "y_hat mean:0.265823 median:0.236802\n",
      "Sensitive TP/(TP+FN) : 0.670000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67       100\n",
      "           1       0.67      0.67      0.67       100\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.67      0.67      0.67       200\n",
      "\n",
      "y_hat mean:0.251672 median:0.208430\n",
      "Sensitive TP/(TP+FN) : 0.700000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70       100\n",
      "           1       0.70      0.70      0.70       100\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       200\n",
      "   macro avg       0.70      0.70      0.70       200\n",
      "weighted avg       0.70      0.70      0.70       200\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat mean:0.272788 median:0.240330\n",
      "Sensitive TP/(TP+FN) : 0.590000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59       100\n",
      "           1       0.59      0.59      0.59       100\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       200\n",
      "   macro avg       0.59      0.59      0.59       200\n",
      "weighted avg       0.59      0.59      0.59       200\n",
      "\n",
      "y_hat mean:0.266517 median:0.243778\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.255215 median:0.228598\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "y_hat mean:0.260265 median:0.228439\n",
      "Sensitive TP/(TP+FN) : 0.690000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       100\n",
      "           1       0.69      0.69      0.69       100\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       200\n",
      "   macro avg       0.69      0.69      0.69       200\n",
      "weighted avg       0.69      0.69      0.69       200\n",
      "\n",
      "y_hat mean:0.261550 median:0.240530\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.266392 median:0.237304\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.258308 median:0.235786\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.257081 median:0.223674\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.275588 median:0.249648\n",
      "Sensitive TP/(TP+FN) : 0.600000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60       100\n",
      "           1       0.60      0.60      0.60       100\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       200\n",
      "   macro avg       0.60      0.60      0.60       200\n",
      "weighted avg       0.60      0.60      0.60       200\n",
      "\n",
      "y_hat mean:0.273762 median:0.239926\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.254772 median:0.234665\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.261426 median:0.228242\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.251273 median:0.202314\n",
      "Sensitive TP/(TP+FN) : 0.700000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70       100\n",
      "           1       0.70      0.70      0.70       100\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       200\n",
      "   macro avg       0.70      0.70      0.70       200\n",
      "weighted avg       0.70      0.70      0.70       200\n",
      "\n",
      "y_hat mean:0.236337 median:0.212436\n",
      "Sensitive TP/(TP+FN) : 0.690000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       100\n",
      "           1       0.69      0.69      0.69       100\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       200\n",
      "   macro avg       0.69      0.69      0.69       200\n",
      "weighted avg       0.69      0.69      0.69       200\n",
      "\n",
      "y_hat mean:0.265255 median:0.217825\n",
      "Sensitive TP/(TP+FN) : 0.700000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70       100\n",
      "           1       0.70      0.70      0.70       100\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       200\n",
      "   macro avg       0.70      0.70      0.70       200\n",
      "weighted avg       0.70      0.70      0.70       200\n",
      "\n",
      "y_hat mean:0.274707 median:0.241453\n",
      "Sensitive TP/(TP+FN) : 0.650000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       100\n",
      "           1       0.65      0.65      0.65       100\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.65      0.65      0.65       200\n",
      "\n",
      "y_hat mean:0.270511 median:0.235621\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.263876 median:0.230579\n",
      "Sensitive TP/(TP+FN) : 0.650000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       100\n",
      "           1       0.65      0.65      0.65       100\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.65      0.65      0.65       200\n",
      "\n",
      "y_hat mean:0.273018 median:0.236355\n",
      "Sensitive TP/(TP+FN) : 0.670000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67       100\n",
      "           1       0.67      0.67      0.67       100\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.67      0.67      0.67       200\n",
      "\n",
      "y_hat mean:0.245153 median:0.197607\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.248892 median:0.212732\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat mean:0.252559 median:0.217235\n",
      "Sensitive TP/(TP+FN) : 0.580000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58       100\n",
      "           1       0.58      0.58      0.58       100\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       200\n",
      "   macro avg       0.58      0.58      0.58       200\n",
      "weighted avg       0.58      0.58      0.58       200\n",
      "\n",
      "y_hat mean:0.300461 median:0.282490\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.253480 median:0.221922\n",
      "Sensitive TP/(TP+FN) : 0.700000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70       100\n",
      "           1       0.70      0.70      0.70       100\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       200\n",
      "   macro avg       0.70      0.70      0.70       200\n",
      "weighted avg       0.70      0.70      0.70       200\n",
      "\n",
      "y_hat mean:0.251960 median:0.230677\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "(10200, 1)\n",
      "(10200, 1)\n",
      "y_hat mean:0.500000 median:0.500000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import json\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from plotLayer import *\n",
    "from preprocess import *\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy import sparse as sp\n",
    "from skimage.measure import block_reduce\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, classification_report, precision_recall_curve\n",
    "\n",
    "from model import *\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "\n",
    "def Classify_Rate(y, y_hat):\n",
    "    # True Positive (TP): we predict a label of 1 (positive), and the true label is 1.\n",
    "    TP = np.sum(np.logical_and(y_hat == 1, y == 1))\n",
    "    # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n",
    "    TN = np.sum(np.logical_and(y_hat == 0, y == 0))\n",
    "    # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n",
    "    FP = np.sum(np.logical_and(y_hat == 1, y == 0))\n",
    "    # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n",
    "    FN = np.sum(np.logical_and(y_hat == 0, y == 1))\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "\n",
    "def Predict(model, x, y_threshold=None):\n",
    "    y_hat = model.predict(x)\n",
    "\n",
    "    if y_threshold :\n",
    "        y_hat[y_hat < y_threshold] = 0\n",
    "        y_hat[y_hat >= y_threshold] = 1\n",
    "    return y_hat\n",
    "\n",
    "def PlotROC(y, y_hat):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(2):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y, y_hat)\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    print (\"roc_auc_score:%f\" %roc_auc_score(y, y_hat))\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[1], tpr[1])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.show()\n",
    "\n",
    "def PreprocessData(datapath, width=256, channel=6):\n",
    "    ratio = 1024 // width\n",
    "    with open(datapath, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    x = np.heaviside(np.array([map(lambda x: block_reduce(x.toarray(), block_size=(ratio,ratio), func=np.max), d.hL) for d in data]), 0)\n",
    "    x = np.swapaxes(x, 1, 3)\n",
    "    y = np.array([d.label for d in data])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    width = 256\n",
    "    channel = 6\n",
    "    #classify_weights_path = \"Classify_epoch_50_batch_4.hdf5\" the below model is copied one directory above\n",
    "    classify_weights_path = \"Baseline_Classify_epoch_100_batch_4.hdf5\"\n",
    "\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "    sess = tf.Session(config=config)\n",
    "    set_session(sess)\n",
    "\n",
    "    classify_model = Encoder_Classify(input_size=(width,width,6), batch_normal=True)\n",
    "    classify_model.load_weights(classify_weights_path)\n",
    "\n",
    "    d0_path = \"../Data/1stDataset/d0*\"\n",
    "    false_path = \"../Data/1stDataset/false*\"\n",
    "    d0 = np.sort(glob.glob(d0_path))\n",
    "    f0 = np.sort(glob.glob(false_path))\n",
    "\n",
    "    y_total = []\n",
    "    y_hat_total = []\n",
    "    #proba is a keyword used in sklearn for probabilities\n",
    "    proba = []\n",
    "#     301\n",
    "    for i in range(500,551):\n",
    "        x1, y1 = PreprocessData(d0[i], width=width, channel=channel)\n",
    "        x2, y2 = PreprocessData(f0[i], width=width, channel=channel)\n",
    "        x = np.concatenate((x1, x2), axis=0)\n",
    "        y = np.concatenate((y1, y2), axis=0)\n",
    "\n",
    "        y_hat = Predict(classify_model, x)\n",
    "#         print(y_hat)\n",
    "        y_total += [y]\n",
    "        y_hat_total += [y_hat]\n",
    "        proba += [y_hat.copy()]\n",
    "# print(proba)-------You should be very careful in numpy as numpy arrays as get cop\n",
    "# https://jakevdp.github.io/PythonDataScienceHandbook/02.02-the-basics-of-numpy-arrays.html\n",
    "# Check the section sub arrays as no copy views\n",
    "        print(\"y_hat mean:%f median:%f\" %(np.mean(y_hat), np.median(y_hat)))\n",
    "        y_hat[y_hat < np.median(y_hat)] = 0\n",
    "        y_hat[y_hat >= np.median(y_hat)] = 1\n",
    "\n",
    "        TP, TN, FP, FN = Classify_Rate(y, y_hat)\n",
    "        print(\"Sensitive TP/(TP+FN) : %f\" %(TP / (TP + FN)))\n",
    "        print(classification_report(y, y_hat))\n",
    "\n",
    "    y = np.concatenate(y_total)\n",
    "    y_hat = np.concatenate(y_hat_total)\n",
    "    proba = np.concatenate(proba)\n",
    "    a=np.hstack((y,proba))\n",
    "    np.savetxt(\"baselinemodel_y_y_hat.txt\",a,delimiter=',')\n",
    "    print(y.shape)\n",
    "    print(y_hat.shape)\n",
    "    print(\"y_hat mean:%f median:%f\" %(np.mean(y_hat), np.median(y_hat)))\n",
    "    fp,tp,tr=roc_curve(y,proba)\n",
    "    p,r,tr1=precision_recall_curve(y,proba)\n",
    "    plt.figure(1)\n",
    "    plt.plot(fp,tp,color='darkorange',lw=2,label='ROC curve(area = %0.3f)'%auc(fp,tp))\n",
    "    plt.xlabel('False positive Rate')\n",
    "    plt.ylabel('True positive Rate')\n",
    "    legend = plt.legend(fontsize = 'x-large')\n",
    "    plt.savefig('ROC_curve_baseline.png')\n",
    "    plt.show()\n",
    "    plt.figure(2)\n",
    "    plt.plot(r,p,color='darkorange', label='Precision recall curve') \n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    legend=plt.legend(fontsize='x-large')\n",
    "    plt.savefig('Precision_Recall_baseline.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC curve area = 0.708"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitive TP/(TP+FN) : 0.655098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66      5100\n",
      "           1       0.66      0.66      0.66      5100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66     10200\n",
      "   macro avg       0.66      0.66      0.66     10200\n",
      "weighted avg       0.66      0.66      0.66     10200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    y_hat[y_hat < np.median(y_hat)] = 0\n",
    "    y_hat[y_hat >= np.median(y_hat)] = 1\n",
    "    TP, TN, FP, FN = Classify_Rate(y, y_hat)\n",
    "    print(\"Sensitive TP/(TP+FN) : %f\" %(TP / (TP + FN)))\n",
    "    print(classification_report(y, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(proba)\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [0.8, 0.9, 0.85, 0]).ravel()\n",
    "# What ever I have presented yesterday those contain thresholded values. \n",
    "# from sklearn.metrics import classification_report\n",
    "# y_true=np.array([0,1,1,1,0,0,1])\n",
    "# y_pred=np.array([0.3,0.9,0.8,0.3,0.2,0.3,0.8])\n",
    "# print(classification_report(y_true, y_pred))\n",
    "#Classification report as well as the confusion_matrix works only for a particular case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
