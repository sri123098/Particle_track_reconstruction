{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 256, 256, 6)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 256, 256, 64)      3520      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 256, 256, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 256, 256, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 128, 128, 128)     512       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 128, 128, 128)     512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 64, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 64, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 16, 16, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 16, 16, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 16, 16, 1024)      9438208   \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 16, 16, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 8, 8, 512)         4719104   \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 4, 4, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 65,511,681\n",
      "Trainable params: 65,482,241\n",
      "Non-trainable params: 29,440\n",
      "_________________________________________________________________\n",
      "y_hat mean:0.144498 median:0.119982\n",
      "Sensitive TP/(TP+FN) : 0.590000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59       100\n",
      "           1       0.59      0.59      0.59       100\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       200\n",
      "   macro avg       0.59      0.59      0.59       200\n",
      "weighted avg       0.59      0.59      0.59       200\n",
      "\n",
      "y_hat mean:0.131413 median:0.104267\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.129692 median:0.102297\n",
      "Sensitive TP/(TP+FN) : 0.690000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       100\n",
      "           1       0.69      0.69      0.69       100\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       200\n",
      "   macro avg       0.69      0.69      0.69       200\n",
      "weighted avg       0.69      0.69      0.69       200\n",
      "\n",
      "y_hat mean:0.131259 median:0.110390\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.135296 median:0.109456\n",
      "Sensitive TP/(TP+FN) : 0.650000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       100\n",
      "           1       0.65      0.65      0.65       100\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.65      0.65      0.65       200\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat mean:0.118468 median:0.108650\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.134109 median:0.103266\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.124908 median:0.099461\n",
      "Sensitive TP/(TP+FN) : 0.570000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.57      0.57       100\n",
      "           1       0.57      0.57      0.57       100\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       200\n",
      "   macro avg       0.57      0.57      0.57       200\n",
      "weighted avg       0.57      0.57      0.57       200\n",
      "\n",
      "y_hat mean:0.136786 median:0.115158\n",
      "Sensitive TP/(TP+FN) : 0.570000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.57      0.57       100\n",
      "           1       0.57      0.57      0.57       100\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       200\n",
      "   macro avg       0.57      0.57      0.57       200\n",
      "weighted avg       0.57      0.57      0.57       200\n",
      "\n",
      "y_hat mean:0.134858 median:0.112403\n",
      "Sensitive TP/(TP+FN) : 0.570000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.57      0.57       100\n",
      "           1       0.57      0.57      0.57       100\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       200\n",
      "   macro avg       0.57      0.57      0.57       200\n",
      "weighted avg       0.57      0.57      0.57       200\n",
      "\n",
      "y_hat mean:0.125057 median:0.102218\n",
      "Sensitive TP/(TP+FN) : 0.610000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       100\n",
      "           1       0.61      0.61      0.61       100\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       200\n",
      "   macro avg       0.61      0.61      0.61       200\n",
      "weighted avg       0.61      0.61      0.61       200\n",
      "\n",
      "y_hat mean:0.128143 median:0.110115\n",
      "Sensitive TP/(TP+FN) : 0.600000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60       100\n",
      "           1       0.60      0.60      0.60       100\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       200\n",
      "   macro avg       0.60      0.60      0.60       200\n",
      "weighted avg       0.60      0.60      0.60       200\n",
      "\n",
      "y_hat mean:0.138914 median:0.126360\n",
      "Sensitive TP/(TP+FN) : 0.570000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.57      0.57       100\n",
      "           1       0.57      0.57      0.57       100\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       200\n",
      "   macro avg       0.57      0.57      0.57       200\n",
      "weighted avg       0.57      0.57      0.57       200\n",
      "\n",
      "y_hat mean:0.128584 median:0.110144\n",
      "Sensitive TP/(TP+FN) : 0.650000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       100\n",
      "           1       0.65      0.65      0.65       100\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.65      0.65      0.65       200\n",
      "\n",
      "y_hat mean:0.132969 median:0.108777\n",
      "Sensitive TP/(TP+FN) : 0.560000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56       100\n",
      "           1       0.56      0.56      0.56       100\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       200\n",
      "   macro avg       0.56      0.56      0.56       200\n",
      "weighted avg       0.56      0.56      0.56       200\n",
      "\n",
      "y_hat mean:0.125818 median:0.110151\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.131658 median:0.114525\n",
      "Sensitive TP/(TP+FN) : 0.610000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       100\n",
      "           1       0.61      0.61      0.61       100\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       200\n",
      "   macro avg       0.61      0.61      0.61       200\n",
      "weighted avg       0.61      0.61      0.61       200\n",
      "\n",
      "y_hat mean:0.136951 median:0.116286\n",
      "Sensitive TP/(TP+FN) : 0.670000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67       100\n",
      "           1       0.67      0.67      0.67       100\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.67      0.67      0.67       200\n",
      "\n",
      "y_hat mean:0.123950 median:0.099092\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "y_hat mean:0.127495 median:0.103485\n",
      "Sensitive TP/(TP+FN) : 0.710000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71       100\n",
      "           1       0.71      0.71      0.71       100\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       200\n",
      "   macro avg       0.71      0.71      0.71       200\n",
      "weighted avg       0.71      0.71      0.71       200\n",
      "\n",
      "y_hat mean:0.126745 median:0.102516\n",
      "Sensitive TP/(TP+FN) : 0.590000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59       100\n",
      "           1       0.59      0.59      0.59       100\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       200\n",
      "   macro avg       0.59      0.59      0.59       200\n",
      "weighted avg       0.59      0.59      0.59       200\n",
      "\n",
      "y_hat mean:0.135852 median:0.118143\n",
      "Sensitive TP/(TP+FN) : 0.580000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58       100\n",
      "           1       0.58      0.58      0.58       100\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       200\n",
      "   macro avg       0.58      0.58      0.58       200\n",
      "weighted avg       0.58      0.58      0.58       200\n",
      "\n",
      "y_hat mean:0.125062 median:0.106258\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.130128 median:0.103761\n",
      "Sensitive TP/(TP+FN) : 0.670000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67       100\n",
      "           1       0.67      0.67      0.67       100\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.67      0.67      0.67       200\n",
      "\n",
      "y_hat mean:0.136913 median:0.115163\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "y_hat mean:0.128045 median:0.102678\n",
      "Sensitive TP/(TP+FN) : 0.570000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.57      0.57       100\n",
      "           1       0.57      0.57      0.57       100\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       200\n",
      "   macro avg       0.57      0.57      0.57       200\n",
      "weighted avg       0.57      0.57      0.57       200\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat mean:0.130226 median:0.108163\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.130347 median:0.106488\n",
      "Sensitive TP/(TP+FN) : 0.610000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       100\n",
      "           1       0.61      0.61      0.61       100\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       200\n",
      "   macro avg       0.61      0.61      0.61       200\n",
      "weighted avg       0.61      0.61      0.61       200\n",
      "\n",
      "y_hat mean:0.123741 median:0.110600\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "y_hat mean:0.125234 median:0.104005\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.133726 median:0.113840\n",
      "Sensitive TP/(TP+FN) : 0.600000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60       100\n",
      "           1       0.60      0.60      0.60       100\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       200\n",
      "   macro avg       0.60      0.60      0.60       200\n",
      "weighted avg       0.60      0.60      0.60       200\n",
      "\n",
      "y_hat mean:0.128289 median:0.107658\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.123861 median:0.106562\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.137826 median:0.118995\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.122608 median:0.098740\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "y_hat mean:0.128734 median:0.102596\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.130044 median:0.109018\n",
      "Sensitive TP/(TP+FN) : 0.640000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       100\n",
      "           1       0.64      0.64      0.64       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.64      0.64      0.64       200\n",
      "\n",
      "y_hat mean:0.134203 median:0.109562\n",
      "Sensitive TP/(TP+FN) : 0.570000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.57      0.57       100\n",
      "           1       0.57      0.57      0.57       100\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       200\n",
      "   macro avg       0.57      0.57      0.57       200\n",
      "weighted avg       0.57      0.57      0.57       200\n",
      "\n",
      "y_hat mean:0.126709 median:0.106085\n",
      "Sensitive TP/(TP+FN) : 0.590000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59       100\n",
      "           1       0.59      0.59      0.59       100\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       200\n",
      "   macro avg       0.59      0.59      0.59       200\n",
      "weighted avg       0.59      0.59      0.59       200\n",
      "\n",
      "y_hat mean:0.122384 median:0.092586\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n",
      "y_hat mean:0.128551 median:0.102694\n",
      "Sensitive TP/(TP+FN) : 0.650000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       100\n",
      "           1       0.65      0.65      0.65       100\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.65      0.65      0.65       200\n",
      "\n",
      "y_hat mean:0.134862 median:0.107466\n",
      "Sensitive TP/(TP+FN) : 0.670000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67       100\n",
      "           1       0.67      0.67      0.67       100\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.67      0.67      0.67       200\n",
      "\n",
      "y_hat mean:0.147138 median:0.116418\n",
      "Sensitive TP/(TP+FN) : 0.610000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       100\n",
      "           1       0.61      0.61      0.61       100\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       200\n",
      "   macro avg       0.61      0.61      0.61       200\n",
      "weighted avg       0.61      0.61      0.61       200\n",
      "\n",
      "y_hat mean:0.128687 median:0.108343\n",
      "Sensitive TP/(TP+FN) : 0.660000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       100\n",
      "           1       0.66      0.66      0.66       100\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n",
      "y_hat mean:0.142012 median:0.110091\n",
      "Sensitive TP/(TP+FN) : 0.650000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       100\n",
      "           1       0.65      0.65      0.65       100\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.65      0.65      0.65       200\n",
      "\n",
      "y_hat mean:0.120309 median:0.102843\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.134686 median:0.106063\n",
      "Sensitive TP/(TP+FN) : 0.630000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       100\n",
      "           1       0.63      0.63      0.63       100\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.63      0.63      0.63       200\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat mean:0.120030 median:0.095946\n",
      "Sensitive TP/(TP+FN) : 0.580000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58       100\n",
      "           1       0.58      0.58      0.58       100\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       200\n",
      "   macro avg       0.58      0.58      0.58       200\n",
      "weighted avg       0.58      0.58      0.58       200\n",
      "\n",
      "y_hat mean:0.140147 median:0.114726\n",
      "Sensitive TP/(TP+FN) : 0.620000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       100\n",
      "           1       0.62      0.62      0.62       100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       200\n",
      "   macro avg       0.62      0.62      0.62       200\n",
      "weighted avg       0.62      0.62      0.62       200\n",
      "\n",
      "y_hat mean:0.131850 median:0.107195\n",
      "Sensitive TP/(TP+FN) : 0.670000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67       100\n",
      "           1       0.67      0.67      0.67       100\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.67      0.67      0.67       200\n",
      "\n",
      "y_hat mean:0.128264 median:0.097355\n",
      "Sensitive TP/(TP+FN) : 0.580000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58       100\n",
      "           1       0.58      0.58      0.58       100\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       200\n",
      "   macro avg       0.58      0.58      0.58       200\n",
      "weighted avg       0.58      0.58      0.58       200\n",
      "\n",
      "(10200, 1)\n",
      "(10200, 1)\n",
      "y_hat mean:0.500000 median:0.500000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import json\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from plotLayer import *\n",
    "from preprocess import *\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy import sparse as sp\n",
    "from skimage.measure import block_reduce\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, classification_report, precision_recall_curve\n",
    "\n",
    "from model import *\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "\n",
    "def Classify_Rate(y, y_hat):\n",
    "    # True Positive (TP): we predict a label of 1 (positive), and the true label is 1.\n",
    "    TP = np.sum(np.logical_and(y_hat == 1, y == 1))\n",
    "    # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n",
    "    TN = np.sum(np.logical_and(y_hat == 0, y == 0))\n",
    "    # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n",
    "    FP = np.sum(np.logical_and(y_hat == 1, y == 0))\n",
    "    # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n",
    "    FN = np.sum(np.logical_and(y_hat == 0, y == 1))\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "\n",
    "def Predict(model, x, y_threshold=None):\n",
    "    y_hat = model.predict(x)\n",
    "\n",
    "    if y_threshold :\n",
    "        y_hat[y_hat < y_threshold] = 0\n",
    "        y_hat[y_hat >= y_threshold] = 1\n",
    "    return y_hat\n",
    "\n",
    "def PlotROC(y, y_hat):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(2):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y, y_hat)\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    print (\"roc_auc_score:%f\" %roc_auc_score(y, y_hat))\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[1], tpr[1])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.show()\n",
    "\n",
    "def PreprocessData(datapath, width=256, channel=6):\n",
    "    ratio = 1024 // width\n",
    "    with open(datapath, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    x = np.heaviside(np.array([map(lambda x: block_reduce(x.toarray(), block_size=(ratio,ratio), func=np.max), d.hL) for d in data]), 0)\n",
    "    x = np.swapaxes(x, 1, 3)\n",
    "    y = np.array([d.label for d in data])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    width = 256\n",
    "    channel = 6\n",
    "    #classify_weights_path = \"Classify_epoch_50_batch_4.hdf5\" the below model is copied one directory above\n",
    "    classify_weights_path = \"Classify_epoch_9_batch_5.hdf5\"\n",
    "\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "    sess = tf.Session(config=config)\n",
    "    set_session(sess)\n",
    "\n",
    "    classify_model = Encoder_Classify(input_size=(width,width,6), batch_normal=True)\n",
    "    classify_model.load_weights(classify_weights_path)\n",
    "\n",
    "    d0_path = \"../Data/1stDataset/d0*\"\n",
    "    false_path = \"../Data/1stDataset/false*\"\n",
    "    d0 = np.sort(glob.glob(d0_path))\n",
    "    f0 = np.sort(glob.glob(false_path))\n",
    "\n",
    "    y_total = []\n",
    "    y_hat_total = []\n",
    "    #proba is a keyword used in sklearn for probabilities\n",
    "    proba = []\n",
    "#     301\n",
    "    for i in range(500,551):\n",
    "        x1, y1 = PreprocessData(d0[i], width=width, channel=channel)\n",
    "        x2, y2 = PreprocessData(f0[i], width=width, channel=channel)\n",
    "        x = np.concatenate((x1, x2), axis=0)\n",
    "        y = np.concatenate((y1, y2), axis=0)\n",
    "\n",
    "        y_hat = Predict(classify_model, x)\n",
    "#         print(y_hat)\n",
    "        y_total += [y]\n",
    "        y_hat_total += [y_hat]\n",
    "        proba += [y_hat.copy()]\n",
    "# print(proba)-------You should be very careful in numpy as numpy arrays as get cop\n",
    "# https://jakevdp.github.io/PythonDataScienceHandbook/02.02-the-basics-of-numpy-arrays.html\n",
    "# Check the section sub arrays as no copy views\n",
    "        print(\"y_hat mean:%f median:%f\" %(np.mean(y_hat), np.median(y_hat)))\n",
    "        y_hat[y_hat < np.median(y_hat)] = 0\n",
    "        y_hat[y_hat >= np.median(y_hat)] = 1\n",
    "\n",
    "        TP, TN, FP, FN = Classify_Rate(y, y_hat)\n",
    "        print(\"Sensitive TP/(TP+FN) : %f\" %(TP / (TP + FN)))\n",
    "        print(classification_report(y, y_hat))\n",
    "\n",
    "    y = np.concatenate(y_total)\n",
    "    y_hat = np.concatenate(y_hat_total)\n",
    "    proba = np.concatenate(proba)\n",
    "    a=np.hstack((y,proba))\n",
    "    np.savetxt(\"newmodel_y_y_hat.txt\",a,delimiter=',')\n",
    "    print(y.shape)\n",
    "    print(y_hat.shape)\n",
    "    print(\"y_hat mean:%f median:%f\" %(np.mean(y_hat), np.median(y_hat)))\n",
    "    fp,tp,tr=roc_curve(y,proba)\n",
    "    p,r,tr1=precision_recall_curve(y,proba)\n",
    "    plt.figure(1)\n",
    "    plt.plot(fp,tp,color='darkorange',lw=2,label='ROC curve(area = %0.3f)'%auc(fp,tp))\n",
    "    plt.xlabel('False positive Rate')\n",
    "    plt.ylabel('True positive Rate')\n",
    "    legend = plt.legend(fontsize = 'x-large')\n",
    "    plt.savefig('ROC_curve_newmodel.png')\n",
    "    plt.show()\n",
    "    plt.figure(2)\n",
    "    plt.plot(r,p,color='darkorange', label='Precision recall curve') \n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    legend=plt.legend(fontsize='x-large')\n",
    "    plt.savefig('Precision_Recall_newmodel.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC curve area with the new model trained on 10 samples= 0.658"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitive TP/(TP+FN) : 0.624118\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62      5100\n",
      "           1       0.62      0.62      0.62      5100\n",
      "\n",
      "   micro avg       0.62      0.62      0.62     10200\n",
      "   macro avg       0.62      0.62      0.62     10200\n",
      "weighted avg       0.62      0.62      0.62     10200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    y_hat[y_hat < np.median(y_hat)] = 0\n",
    "    y_hat[y_hat >= np.median(y_hat)] = 1\n",
    "    TP, TN, FP, FN = Classify_Rate(y, y_hat)\n",
    "    print(\"Sensitive TP/(TP+FN) : %f\" %(TP / (TP + FN)))\n",
    "    print(classification_report(y, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(proba)\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [0.8, 0.9, 0.85, 0]).ravel()\n",
    "# What ever I have presented yesterday those contain thresholded values. \n",
    "# from sklearn.metrics import classification_report\n",
    "# y_true=np.array([0,1,1,1,0,0,1])\n",
    "# y_pred=np.array([0.3,0.9,0.8,0.3,0.2,0.3,0.8])\n",
    "# print(classification_report(y_true, y_pred))\n",
    "#Classification report as well as the confusion_matrix works only for a particular case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
